{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 檢查Dataset 的描述與資訊\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1_l2\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# INPUT = x_train.shape[1:]\n",
    "def build_mlp_CNN(input_shape, output_units=10,ratio=0.01,ratio2=0.01,drop_r=0.2,do_NB = True):\n",
    "    model = Sequential()\n",
    "    #   第二步：構建網絡層\n",
    "    if do_NB == True:\n",
    "        \n",
    "        model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(drop_r))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "       \n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(drop_r))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units = 512,activation=\"relu\",kernel_regularizer=l1_l2(ratio,ratio2)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(drop_r))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(output_units)) # 輸出結果是10個類別，所以維度是10   \n",
    "        model.add(Activation('softmax')) # 最後一層用softmax作為激活函數\n",
    "    else:\n",
    "        model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units = 512,activation=\"relu\",kernel_regularizer=l1_l2(ratio,ratio2)))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dropout(drop))\n",
    "        model.add(Dense(output_units)) # 輸出結果是10個類別，所以維度是10   \n",
    "        model.add(Activation('softmax')) # 最後一層用softmax作為激活函數\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp_CNN(x_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_classes = 10\n",
    "EPOCHS = 20\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "L1_EXP = [1e-2, 0]\n",
    "L2_EXP = [1e-2, 0]\n",
    "Dropout_EXP = [0.2,0.5]\n",
    "OPTIMIZER = ['SGD','Adam']\n",
    "do_NB = [True,False]\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 載入 Callbacks, 並將 monitor 設定為監控 validation loss\n",
    "\"\"\"\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", \n",
    "                          patience=5, \n",
    "                          verbose=1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/iris168/anaconda3/envs/tesnoflow_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 108.0204 - acc: 0.3803 - val_loss: 10.0891 - val_acc: 0.2938\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 6.2258 - acc: 0.4284 - val_loss: 6.1388 - val_acc: 0.4164\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 5.6012 - acc: 0.4817 - val_loss: 5.6257 - val_acc: 0.4607\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 5.2913 - acc: 0.5184 - val_loss: 4.9547 - val_acc: 0.5231\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 4.3205 - acc: 0.5549 - val_loss: 4.4523 - val_acc: 0.5241\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 3.8802 - acc: 0.5717 - val_loss: 4.5354 - val_acc: 0.4380\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 3.7003 - acc: 0.5828 - val_loss: 3.7713 - val_acc: 0.5769\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.5748 - acc: 0.5939 - val_loss: 3.9456 - val_acc: 0.5195\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.4868 - acc: 0.6082 - val_loss: 4.0405 - val_acc: 0.5201\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.4071 - acc: 0.6155 - val_loss: 3.4892 - val_acc: 0.6160\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.3496 - acc: 0.6235 - val_loss: 3.4506 - val_acc: 0.6196\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 3.2705 - acc: 0.6311 - val_loss: 3.4807 - val_acc: 0.6078\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.2515 - acc: 0.6318 - val_loss: 3.3816 - val_acc: 0.6249\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.2021 - acc: 0.6410 - val_loss: 3.4434 - val_acc: 0.5765\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.1599 - acc: 0.6444 - val_loss: 3.3833 - val_acc: 0.6171\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.1491 - acc: 0.6486 - val_loss: 3.3054 - val_acc: 0.6011\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.1077 - acc: 0.6526 - val_loss: 3.2132 - val_acc: 0.6584\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.0818 - acc: 0.6599 - val_loss: 3.1186 - val_acc: 0.6535\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.0534 - acc: 0.6635 - val_loss: 3.2568 - val_acc: 0.6285\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.0448 - acc: 0.6667 - val_loss: 3.1299 - val_acc: 0.6618\n",
      "l1-0.01 l2-0.01 drop-0.2 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 109.8719 - acc: 0.3740 - val_loss: 12.0597 - val_acc: 0.3548\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 6.9304 - acc: 0.4225 - val_loss: 7.5399 - val_acc: 0.3294\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 5.7448 - acc: 0.4768 - val_loss: 5.4376 - val_acc: 0.4481\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.6336 - acc: 0.5239 - val_loss: 4.9883 - val_acc: 0.4403\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 4.1183 - acc: 0.5513 - val_loss: 4.2423 - val_acc: 0.5494\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.9051 - acc: 0.5688 - val_loss: 4.4275 - val_acc: 0.4625\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.7382 - acc: 0.5835 - val_loss: 3.8309 - val_acc: 0.5653\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.6249 - acc: 0.5970 - val_loss: 3.9866 - val_acc: 0.5443\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.5352 - acc: 0.6052 - val_loss: 3.7344 - val_acc: 0.5536\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.4705 - acc: 0.6112 - val_loss: 3.7992 - val_acc: 0.5662\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.3892 - acc: 0.6197 - val_loss: 3.4417 - val_acc: 0.6092\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.3307 - acc: 0.6276 - val_loss: 3.6759 - val_acc: 0.6032\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.2822 - acc: 0.6322 - val_loss: 3.5678 - val_acc: 0.6080\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.2410 - acc: 0.6411 - val_loss: 3.2825 - val_acc: 0.6324\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.2142 - acc: 0.6443 - val_loss: 3.2871 - val_acc: 0.6368\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1701 - acc: 0.6491 - val_loss: 3.2761 - val_acc: 0.6459\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1530 - acc: 0.6551 - val_loss: 3.3710 - val_acc: 0.6287\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1144 - acc: 0.6593 - val_loss: 3.4056 - val_acc: 0.5984\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1007 - acc: 0.6621 - val_loss: 3.1011 - val_acc: 0.6773\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.0681 - acc: 0.6667 - val_loss: 3.1417 - val_acc: 0.6595\n",
      "l1-0.01 l2-0 drop-0.2 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 9.6441 - acc: 0.3604 - val_loss: 8.6442 - val_acc: 0.4666\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 8.1036 - acc: 0.4830 - val_loss: 7.4133 - val_acc: 0.5415\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 6.9920 - acc: 0.5354 - val_loss: 6.5277 - val_acc: 0.5390\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 6.0664 - acc: 0.5748 - val_loss: 5.7525 - val_acc: 0.5607\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.2773 - acc: 0.6059 - val_loss: 4.9460 - val_acc: 0.6179\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.6090 - acc: 0.6326 - val_loss: 4.5185 - val_acc: 0.5734\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.0298 - acc: 0.6582 - val_loss: 3.7510 - val_acc: 0.6815\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.5370 - acc: 0.6772 - val_loss: 3.2997 - val_acc: 0.6971\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1168 - acc: 0.6938 - val_loss: 2.9278 - val_acc: 0.7052\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 2.7525 - acc: 0.7106 - val_loss: 2.7189 - val_acc: 0.6695\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 2.4375 - acc: 0.7242 - val_loss: 2.3110 - val_acc: 0.7329\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 2.1679 - acc: 0.7379 - val_loss: 2.0936 - val_acc: 0.7298\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.9319 - acc: 0.7496 - val_loss: 1.8662 - val_acc: 0.7435\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.7316 - acc: 0.7628 - val_loss: 1.7007 - val_acc: 0.7523\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.5515 - acc: 0.7753 - val_loss: 1.5907 - val_acc: 0.7417\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.4001 - acc: 0.7851 - val_loss: 1.4284 - val_acc: 0.7616\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2667 - acc: 0.7982 - val_loss: 1.3079 - val_acc: 0.7720\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.1484 - acc: 0.8063 - val_loss: 1.2658 - val_acc: 0.7578\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.0500 - acc: 0.8163 - val_loss: 1.1710 - val_acc: 0.7661\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.9612 - acc: 0.8271 - val_loss: 1.0939 - val_acc: 0.7749\n",
      "l1-0 l2-0.01 drop-0.2 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.8643 - acc: 0.3666 - val_loss: 1.5139 - val_acc: 0.4576\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.4522 - acc: 0.4868 - val_loss: 1.4250 - val_acc: 0.4980\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.3106 - acc: 0.5341 - val_loss: 1.4013 - val_acc: 0.5166\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.2133 - acc: 0.5686 - val_loss: 1.5685 - val_acc: 0.4688\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.1339 - acc: 0.5969 - val_loss: 1.3501 - val_acc: 0.5167\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.0666 - acc: 0.6228 - val_loss: 1.1072 - val_acc: 0.6078\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.0146 - acc: 0.6404 - val_loss: 1.0323 - val_acc: 0.6261\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.9716 - acc: 0.6570 - val_loss: 1.0586 - val_acc: 0.6237\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.9361 - acc: 0.6685 - val_loss: 1.3140 - val_acc: 0.5452\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.9013 - acc: 0.6805 - val_loss: 0.8944 - val_acc: 0.6864\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.8743 - acc: 0.6917 - val_loss: 1.0760 - val_acc: 0.6263\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.8466 - acc: 0.7024 - val_loss: 0.8789 - val_acc: 0.6911\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.8218 - acc: 0.7126 - val_loss: 0.8137 - val_acc: 0.7174\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.8004 - acc: 0.7171 - val_loss: 0.8722 - val_acc: 0.6987\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.7865 - acc: 0.7226 - val_loss: 0.8556 - val_acc: 0.7020\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.7705 - acc: 0.7283 - val_loss: 1.2198 - val_acc: 0.5868\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.7512 - acc: 0.7360 - val_loss: 0.7760 - val_acc: 0.7314\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.7254 - acc: 0.7436 - val_loss: 0.8164 - val_acc: 0.7133\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.7157 - acc: 0.7487 - val_loss: 0.7904 - val_acc: 0.7236\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.6995 - acc: 0.7553 - val_loss: 0.7533 - val_acc: 0.7345\n",
      "l1-0 l2-0 drop-0.2 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 108.5379 - acc: 0.2680 - val_loss: 11.8809 - val_acc: 0.3219\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 8.4942 - acc: 0.3593 - val_loss: 8.2538 - val_acc: 0.3013\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 7.4879 - acc: 0.4043 - val_loss: 7.7144 - val_acc: 0.4180\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 6.7512 - acc: 0.4318 - val_loss: 6.8604 - val_acc: 0.3928\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 6.1472 - acc: 0.4439 - val_loss: 6.5494 - val_acc: 0.3757\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 5.7381 - acc: 0.4632 - val_loss: 6.2221 - val_acc: 0.3438\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.4829 - acc: 0.4752 - val_loss: 6.1285 - val_acc: 0.4016\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.3162 - acc: 0.4866 - val_loss: 6.2989 - val_acc: 0.3160\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.2189 - acc: 0.4955 - val_loss: 5.3180 - val_acc: 0.5331\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.1294 - acc: 0.5027 - val_loss: 5.6069 - val_acc: 0.3972\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.0661 - acc: 0.5137 - val_loss: 5.4638 - val_acc: 0.4710\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.9889 - acc: 0.5191 - val_loss: 5.0946 - val_acc: 0.5338\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.9276 - acc: 0.5251 - val_loss: 5.3414 - val_acc: 0.4585\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.8452 - acc: 0.5328 - val_loss: 5.2523 - val_acc: 0.5207\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.8089 - acc: 0.5355 - val_loss: 5.0787 - val_acc: 0.5500\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.7724 - acc: 0.5395 - val_loss: 5.1236 - val_acc: 0.5732\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.7413 - acc: 0.5451 - val_loss: 5.0475 - val_acc: 0.5415\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.7179 - acc: 0.5494 - val_loss: 5.0477 - val_acc: 0.5394\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.6924 - acc: 0.5537 - val_loss: 5.1618 - val_acc: 0.5406\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.6717 - acc: 0.5569 - val_loss: 5.0710 - val_acc: 0.5148\n",
      "l1-0.01 l2-0.01 drop-0.5 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 110.3055 - acc: 0.2685 - val_loss: 13.1255 - val_acc: 0.2628\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 8.3922 - acc: 0.3637 - val_loss: 8.3606 - val_acc: 0.2240\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 7.2766 - acc: 0.3939 - val_loss: 7.7760 - val_acc: 0.3298\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 6.7624 - acc: 0.4236 - val_loss: 7.0881 - val_acc: 0.3746\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 6.2013 - acc: 0.4426 - val_loss: 6.3097 - val_acc: 0.4283\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.8323 - acc: 0.4581 - val_loss: 5.7551 - val_acc: 0.4849\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.5371 - acc: 0.4686 - val_loss: 5.7321 - val_acc: 0.4829\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.3619 - acc: 0.4804 - val_loss: 5.3538 - val_acc: 0.5102\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 5.2543 - acc: 0.4931 - val_loss: 5.4341 - val_acc: 0.4714\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 5.1658 - acc: 0.4993 - val_loss: 5.4720 - val_acc: 0.4749\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.0972 - acc: 0.5077 - val_loss: 5.6260 - val_acc: 0.4094\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.0015 - acc: 0.5136 - val_loss: 5.9395 - val_acc: 0.4124\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.9797 - acc: 0.5209 - val_loss: 5.0818 - val_acc: 0.5493\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.9417 - acc: 0.5295 - val_loss: 4.8853 - val_acc: 0.5089\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.8937 - acc: 0.5277 - val_loss: 5.2217 - val_acc: 0.5056\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.8523 - acc: 0.5363 - val_loss: 5.1701 - val_acc: 0.5137\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 4.8232 - acc: 0.5413 - val_loss: 5.3601 - val_acc: 0.4659\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.7730 - acc: 0.5480 - val_loss: 4.9544 - val_acc: 0.5260\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.7369 - acc: 0.5528 - val_loss: 4.9366 - val_acc: 0.5744\n",
      "Epoch 00019: early stopping\n",
      "l1-0.01 l2-0 drop-0.5 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 10.0495 - acc: 0.2422 - val_loss: 9.1651 - val_acc: 0.2904\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 8.4706 - acc: 0.3515 - val_loss: 7.7702 - val_acc: 0.4046\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 7.3293 - acc: 0.4037 - val_loss: 6.8880 - val_acc: 0.4136\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 6.4046 - acc: 0.4407 - val_loss: 5.9432 - val_acc: 0.4721\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 5.6274 - acc: 0.4722 - val_loss: 5.3770 - val_acc: 0.4318\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.9685 - acc: 0.4898 - val_loss: 4.6868 - val_acc: 0.5093\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.4089 - acc: 0.5087 - val_loss: 4.2041 - val_acc: 0.4840\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.9322 - acc: 0.5256 - val_loss: 3.8242 - val_acc: 0.5001\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.5180 - acc: 0.5367 - val_loss: 3.2690 - val_acc: 0.5613\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 3.1642 - acc: 0.5485 - val_loss: 3.0627 - val_acc: 0.5352\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 2.8530 - acc: 0.5648 - val_loss: 2.7843 - val_acc: 0.5534\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 2.5865 - acc: 0.5776 - val_loss: 2.7330 - val_acc: 0.4861\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 2.3573 - acc: 0.5884 - val_loss: 2.2544 - val_acc: 0.5936\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 2.1522 - acc: 0.6027 - val_loss: 2.0522 - val_acc: 0.6072\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.9851 - acc: 0.6116 - val_loss: 2.0842 - val_acc: 0.5580\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.8359 - acc: 0.6214 - val_loss: 1.7322 - val_acc: 0.6419\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.7064 - acc: 0.6296 - val_loss: 1.7107 - val_acc: 0.6132\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.5973 - acc: 0.6372 - val_loss: 1.8396 - val_acc: 0.5356\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.4948 - acc: 0.6448 - val_loss: 1.5155 - val_acc: 0.6269\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.4061 - acc: 0.6527 - val_loss: 1.2849 - val_acc: 0.6911\n",
      "l1-0 l2-0.01 drop-0.5 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 2.2804 - acc: 0.2516 - val_loss: 1.8412 - val_acc: 0.3160\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.7962 - acc: 0.3585 - val_loss: 1.5155 - val_acc: 0.4365\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.6125 - acc: 0.4116 - val_loss: 1.4656 - val_acc: 0.4672\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.5225 - acc: 0.4430 - val_loss: 1.6005 - val_acc: 0.4456\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.4610 - acc: 0.4663 - val_loss: 1.3878 - val_acc: 0.4905\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.4145 - acc: 0.4857 - val_loss: 1.3964 - val_acc: 0.4909\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.3812 - acc: 0.4980 - val_loss: 2.0539 - val_acc: 0.3185\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.3518 - acc: 0.5103 - val_loss: 1.3408 - val_acc: 0.5301\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.3205 - acc: 0.5212 - val_loss: 1.5924 - val_acc: 0.4518\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2955 - acc: 0.5298 - val_loss: 1.3755 - val_acc: 0.4984\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2688 - acc: 0.5419 - val_loss: 1.6836 - val_acc: 0.4257\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2439 - acc: 0.5503 - val_loss: 1.2118 - val_acc: 0.5543\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2159 - acc: 0.5621 - val_loss: 1.6103 - val_acc: 0.4482\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2012 - acc: 0.5675 - val_loss: 1.1101 - val_acc: 0.6045\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1800 - acc: 0.5757 - val_loss: 1.1452 - val_acc: 0.5941\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1627 - acc: 0.5823 - val_loss: 1.1763 - val_acc: 0.5677\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1395 - acc: 0.5901 - val_loss: 1.1746 - val_acc: 0.5849\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1292 - acc: 0.5943 - val_loss: 1.0752 - val_acc: 0.6214\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1073 - acc: 0.6038 - val_loss: 1.1756 - val_acc: 0.5933\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.0941 - acc: 0.6077 - val_loss: 1.0365 - val_acc: 0.6284\n",
      "l1-0 l2-0 drop-0.5 opt-SGD do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 23.0013 - acc: 0.4186 - val_loss: 8.6122 - val_acc: 0.4690\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 7.4100 - acc: 0.5357 - val_loss: 6.4058 - val_acc: 0.5173\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 5.7838 - acc: 0.5885 - val_loss: 5.4776 - val_acc: 0.5846\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 5.1727 - acc: 0.6180 - val_loss: 5.2139 - val_acc: 0.5799\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.8130 - acc: 0.6423 - val_loss: 4.7656 - val_acc: 0.6094\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.5590 - acc: 0.6550 - val_loss: 4.5328 - val_acc: 0.6608\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.4008 - acc: 0.6691 - val_loss: 4.5057 - val_acc: 0.6450\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.2707 - acc: 0.6808 - val_loss: 4.1944 - val_acc: 0.6702\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.1854 - acc: 0.6895 - val_loss: 4.1258 - val_acc: 0.7074\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.0818 - acc: 0.6987 - val_loss: 4.0513 - val_acc: 0.6955\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 4.0286 - acc: 0.7055 - val_loss: 4.1439 - val_acc: 0.6586\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 3.9629 - acc: 0.7122 - val_loss: 4.0903 - val_acc: 0.6800\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 108s 2ms/step - loss: 3.9328 - acc: 0.7203 - val_loss: 3.8903 - val_acc: 0.7114\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.9030 - acc: 0.7215 - val_loss: 3.9531 - val_acc: 0.7033\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.8553 - acc: 0.7259 - val_loss: 3.9963 - val_acc: 0.6930\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 3.8002 - acc: 0.7312 - val_loss: 3.9164 - val_acc: 0.7119\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.8008 - acc: 0.7352 - val_loss: 3.8738 - val_acc: 0.7193\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.7679 - acc: 0.7359 - val_loss: 3.8147 - val_acc: 0.7279\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.7173 - acc: 0.7409 - val_loss: 3.9169 - val_acc: 0.6975\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 3.7014 - acc: 0.7412 - val_loss: 3.9084 - val_acc: 0.6911\n",
      "l1-0.01 l2-0.01 drop-0.2 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 23.2420 - acc: 0.4170 - val_loss: 8.3837 - val_acc: 0.4309\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 6.7020 - acc: 0.5511 - val_loss: 6.0176 - val_acc: 0.5697\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 5.4847 - acc: 0.5999 - val_loss: 5.2515 - val_acc: 0.5900\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 5.0368 - acc: 0.6260 - val_loss: 4.8361 - val_acc: 0.6183\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 4.6909 - acc: 0.6432 - val_loss: 4.5258 - val_acc: 0.6452\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 4.4485 - acc: 0.6630 - val_loss: 4.4120 - val_acc: 0.6192\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 4.2546 - acc: 0.6753 - val_loss: 4.0929 - val_acc: 0.6774\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 4.1115 - acc: 0.6860 - val_loss: 4.2676 - val_acc: 0.6501\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 4.0649 - acc: 0.6937 - val_loss: 4.0235 - val_acc: 0.6873\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.9702 - acc: 0.7040 - val_loss: 4.1751 - val_acc: 0.6426\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.9068 - acc: 0.7120 - val_loss: 3.7595 - val_acc: 0.7243\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.8686 - acc: 0.7179 - val_loss: 4.1572 - val_acc: 0.6583\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.8961 - acc: 0.7209 - val_loss: 4.0203 - val_acc: 0.7061\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.8407 - acc: 0.7275 - val_loss: 3.8234 - val_acc: 0.7089\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.7730 - acc: 0.7315 - val_loss: 3.7308 - val_acc: 0.7300\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.7639 - acc: 0.7328 - val_loss: 3.8876 - val_acc: 0.6996\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.7030 - acc: 0.7375 - val_loss: 3.6435 - val_acc: 0.7263\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.6866 - acc: 0.7385 - val_loss: 3.8060 - val_acc: 0.7052\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 3.6756 - acc: 0.7466 - val_loss: 3.6452 - val_acc: 0.7512\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.6709 - acc: 0.7480 - val_loss: 4.0791 - val_acc: 0.6456\n",
      "l1-0.01 l2-0 drop-0.2 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 3.7578 - acc: 0.5005 - val_loss: 1.9766 - val_acc: 0.4965\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5360 - acc: 0.6460 - val_loss: 1.5791 - val_acc: 0.6264\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.3982 - acc: 0.6899 - val_loss: 1.3440 - val_acc: 0.7112\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.3276 - acc: 0.7138 - val_loss: 1.2858 - val_acc: 0.7236\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.2912 - acc: 0.7292 - val_loss: 1.3857 - val_acc: 0.6942\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.2593 - acc: 0.7407 - val_loss: 1.3156 - val_acc: 0.7268\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 1.2533 - acc: 0.7458 - val_loss: 1.4645 - val_acc: 0.6769\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 118s 2ms/step - loss: 1.2098 - acc: 0.7591 - val_loss: 1.2836 - val_acc: 0.7436\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 1.2001 - acc: 0.7660 - val_loss: 1.2775 - val_acc: 0.7292\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.1772 - acc: 0.7701 - val_loss: 1.2325 - val_acc: 0.7441\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 1.1495 - acc: 0.7767 - val_loss: 1.3391 - val_acc: 0.7225\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 1.1322 - acc: 0.7835 - val_loss: 1.1584 - val_acc: 0.7739\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 1.1155 - acc: 0.7864 - val_loss: 1.1479 - val_acc: 0.7748\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.1081 - acc: 0.7882 - val_loss: 1.1516 - val_acc: 0.7716\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.0767 - acc: 0.7953 - val_loss: 1.1973 - val_acc: 0.7653\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.0682 - acc: 0.7996 - val_loss: 1.1009 - val_acc: 0.7826\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.0513 - acc: 0.8033 - val_loss: 1.0978 - val_acc: 0.7818\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.0335 - acc: 0.8072 - val_loss: 1.0894 - val_acc: 0.7846\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.0163 - acc: 0.8062 - val_loss: 1.1034 - val_acc: 0.7791\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.9934 - acc: 0.8124 - val_loss: 1.0825 - val_acc: 0.7760\n",
      "l1-0 l2-0.01 drop-0.2 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.4413 - acc: 0.5059 - val_loss: 1.3578 - val_acc: 0.5321\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.9341 - acc: 0.6695 - val_loss: 0.8378 - val_acc: 0.7070\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.7726 - acc: 0.7289 - val_loss: 0.8150 - val_acc: 0.7193\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.6588 - acc: 0.7704 - val_loss: 0.8274 - val_acc: 0.7229\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.5737 - acc: 0.7997 - val_loss: 0.7253 - val_acc: 0.7477\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.4996 - acc: 0.8262 - val_loss: 0.7153 - val_acc: 0.7547\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.4387 - acc: 0.8455 - val_loss: 0.6288 - val_acc: 0.7884\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.3843 - acc: 0.8654 - val_loss: 0.6263 - val_acc: 0.7908\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.3408 - acc: 0.8793 - val_loss: 0.6616 - val_acc: 0.7850\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.3030 - acc: 0.8932 - val_loss: 0.7831 - val_acc: 0.7506\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.2647 - acc: 0.9053 - val_loss: 0.6907 - val_acc: 0.7904\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.2392 - acc: 0.9156 - val_loss: 0.6744 - val_acc: 0.7900\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.2180 - acc: 0.9229 - val_loss: 0.8383 - val_acc: 0.7671\n",
      "Epoch 00013: early stopping\n",
      "l1-0 l2-0 drop-0.2 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 25.0938 - acc: 0.3506 - val_loss: 10.2886 - val_acc: 0.3785\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 9.0472 - acc: 0.4485 - val_loss: 8.1320 - val_acc: 0.4670\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 8.0292 - acc: 0.4966 - val_loss: 7.7721 - val_acc: 0.5200\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 7.8230 - acc: 0.5271 - val_loss: 7.6553 - val_acc: 0.5297\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 7.7025 - acc: 0.5423 - val_loss: 7.4841 - val_acc: 0.5276\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 7.5369 - acc: 0.5621 - val_loss: 7.3528 - val_acc: 0.5905\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 7.4224 - acc: 0.5750 - val_loss: 7.2733 - val_acc: 0.5935\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 7.3340 - acc: 0.5844 - val_loss: 7.4970 - val_acc: 0.5748\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 7.1627 - acc: 0.5936 - val_loss: 6.9648 - val_acc: 0.6486\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 7.1105 - acc: 0.6021 - val_loss: 6.8304 - val_acc: 0.6113\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.9858 - acc: 0.6099 - val_loss: 6.9251 - val_acc: 0.6322\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.9536 - acc: 0.6150 - val_loss: 6.8009 - val_acc: 0.6595\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.7920 - acc: 0.6181 - val_loss: 6.6478 - val_acc: 0.6417\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.6804 - acc: 0.6247 - val_loss: 6.2396 - val_acc: 0.6815\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.5819 - acc: 0.6302 - val_loss: 6.5665 - val_acc: 0.6041\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.5946 - acc: 0.6324 - val_loss: 6.5730 - val_acc: 0.6755\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 6.5684 - acc: 0.6370 - val_loss: 6.4972 - val_acc: 0.6323\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 6.4389 - acc: 0.6396 - val_loss: 6.3693 - val_acc: 0.6417\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 6.4222 - acc: 0.6431 - val_loss: 6.4728 - val_acc: 0.6262\n",
      "Epoch 00019: early stopping\n",
      "l1-0.01 l2-0.01 drop-0.5 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 25.1610 - acc: 0.3545 - val_loss: 10.2879 - val_acc: 0.4117\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 9.0818 - acc: 0.4552 - val_loss: 8.5278 - val_acc: 0.4871\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 8.3191 - acc: 0.4977 - val_loss: 8.0570 - val_acc: 0.5210\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 8.0024 - acc: 0.5238 - val_loss: 7.8951 - val_acc: 0.5184\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 7.8167 - acc: 0.5448 - val_loss: 7.9928 - val_acc: 0.5323\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 7.7205 - acc: 0.5647 - val_loss: 7.6066 - val_acc: 0.5766\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 115s 2ms/step - loss: 7.6086 - acc: 0.5758 - val_loss: 7.5015 - val_acc: 0.5809\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 7.4523 - acc: 0.5877 - val_loss: 7.2703 - val_acc: 0.5919\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 7.3154 - acc: 0.5998 - val_loss: 7.4759 - val_acc: 0.5636\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 7.1957 - acc: 0.6064 - val_loss: 6.9189 - val_acc: 0.6020\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 7.0308 - acc: 0.6156 - val_loss: 7.1492 - val_acc: 0.6071\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 115s 2ms/step - loss: 6.9817 - acc: 0.6146 - val_loss: 6.8377 - val_acc: 0.6422\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 113s 2ms/step - loss: 6.8743 - acc: 0.6251 - val_loss: 6.6772 - val_acc: 0.6473\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 6.8191 - acc: 0.6265 - val_loss: 6.8665 - val_acc: 0.5976\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 6.6859 - acc: 0.6309 - val_loss: 6.7129 - val_acc: 0.6513\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 6.5977 - acc: 0.6359 - val_loss: 6.5973 - val_acc: 0.6493\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 6.6420 - acc: 0.6388 - val_loss: 6.7232 - val_acc: 0.6742\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 6.6169 - acc: 0.6435 - val_loss: 6.3683 - val_acc: 0.6746\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 6.5292 - acc: 0.6451 - val_loss: 6.3015 - val_acc: 0.6710\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 113s 2ms/step - loss: 6.4441 - acc: 0.6497 - val_loss: 6.6017 - val_acc: 0.6513\n",
      "l1-0.01 l2-0 drop-0.5 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 111s 2ms/step - loss: 4.4039 - acc: 0.4078 - val_loss: 2.4564 - val_acc: 0.3950\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 1.9033 - acc: 0.5504 - val_loss: 1.9639 - val_acc: 0.5322\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 1.7468 - acc: 0.6058 - val_loss: 1.6619 - val_acc: 0.6262\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.6897 - acc: 0.6316 - val_loss: 1.7004 - val_acc: 0.6322\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.6390 - acc: 0.6523 - val_loss: 1.5305 - val_acc: 0.6920\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.6253 - acc: 0.6642 - val_loss: 1.5043 - val_acc: 0.7096\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 1.6036 - acc: 0.6736 - val_loss: 1.5731 - val_acc: 0.6808\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5895 - acc: 0.6790 - val_loss: 1.5528 - val_acc: 0.7034\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5772 - acc: 0.6865 - val_loss: 1.4903 - val_acc: 0.7240\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5628 - acc: 0.6920 - val_loss: 1.5601 - val_acc: 0.6912\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5480 - acc: 0.7003 - val_loss: 1.5140 - val_acc: 0.7100\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 1.5385 - acc: 0.7002 - val_loss: 1.4418 - val_acc: 0.7278\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5270 - acc: 0.7038 - val_loss: 1.5997 - val_acc: 0.6768\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5200 - acc: 0.7099 - val_loss: 1.4341 - val_acc: 0.7414\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5131 - acc: 0.7133 - val_loss: 1.5303 - val_acc: 0.7082\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.5045 - acc: 0.7156 - val_loss: 1.5387 - val_acc: 0.7138\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.4978 - acc: 0.7183 - val_loss: 1.4881 - val_acc: 0.7215\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 1.4773 - acc: 0.7244 - val_loss: 1.3881 - val_acc: 0.7497\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.4780 - acc: 0.7240 - val_loss: 1.3962 - val_acc: 0.7569\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.4797 - acc: 0.7256 - val_loss: 1.5445 - val_acc: 0.7035\n",
      "l1-0 l2-0.01 drop-0.5 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,253,674\n",
      "Trainable params: 1,252,266\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 1.7293 - acc: 0.4071 - val_loss: 1.3219 - val_acc: 0.5154\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.2652 - acc: 0.5425 - val_loss: 1.1886 - val_acc: 0.5632\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.1065 - acc: 0.6035 - val_loss: 0.9904 - val_acc: 0.6444\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.0004 - acc: 0.6457 - val_loss: 0.8836 - val_acc: 0.6884\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.9163 - acc: 0.6767 - val_loss: 1.0319 - val_acc: 0.6337\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.8548 - acc: 0.6966 - val_loss: 0.7866 - val_acc: 0.7187\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.8177 - acc: 0.7106 - val_loss: 0.7587 - val_acc: 0.7346\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.7820 - acc: 0.7252 - val_loss: 0.7306 - val_acc: 0.7504\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.7525 - acc: 0.7365 - val_loss: 0.7279 - val_acc: 0.7539\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.7260 - acc: 0.7432 - val_loss: 0.7035 - val_acc: 0.7593\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.6966 - acc: 0.7543 - val_loss: 0.9051 - val_acc: 0.6855\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.6858 - acc: 0.7598 - val_loss: 0.6119 - val_acc: 0.7897\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.6682 - acc: 0.7656 - val_loss: 0.6532 - val_acc: 0.7758\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.6558 - acc: 0.7713 - val_loss: 0.6191 - val_acc: 0.7919\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.6421 - acc: 0.7734 - val_loss: 0.6769 - val_acc: 0.7617\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.6253 - acc: 0.7827 - val_loss: 0.6880 - val_acc: 0.7652\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.6184 - acc: 0.7817 - val_loss: 0.6390 - val_acc: 0.7820\n",
      "Epoch 00017: early stopping\n",
      "l1-0 l2-0 drop-0.5 opt-Adam do_nb-True\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 119.8164 - acc: 0.1000 - val_loss: 18.6228 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 4.2082 - acc: 0.1439 - val_loss: 2.9347 - val_acc: 0.1384\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.8408 - acc: 0.2207 - val_loss: 2.9208 - val_acc: 0.1933\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.7471 - acc: 0.2444 - val_loss: 2.6762 - val_acc: 0.2680\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6905 - acc: 0.2553 - val_loss: 2.6354 - val_acc: 0.2668\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6637 - acc: 0.2586 - val_loss: 2.6186 - val_acc: 0.2842\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6506 - acc: 0.2583 - val_loss: 2.6944 - val_acc: 0.2495\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6475 - acc: 0.2692 - val_loss: 2.6098 - val_acc: 0.2892\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6315 - acc: 0.2932 - val_loss: 2.6033 - val_acc: 0.3302\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6052 - acc: 0.3076 - val_loss: 2.7071 - val_acc: 0.2659\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.5898 - acc: 0.3165 - val_loss: 2.6687 - val_acc: 0.2913\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.5660 - acc: 0.3275 - val_loss: 2.5625 - val_acc: 0.3263\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.5508 - acc: 0.3342 - val_loss: 2.4619 - val_acc: 0.3640\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.5339 - acc: 0.3432 - val_loss: 2.4695 - val_acc: 0.3715\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.5191 - acc: 0.3503 - val_loss: 2.5039 - val_acc: 0.3738\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.4977 - acc: 0.3604 - val_loss: 2.4115 - val_acc: 0.4020\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.4758 - acc: 0.3697 - val_loss: 2.5632 - val_acc: 0.3799\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.4734 - acc: 0.3758 - val_loss: 2.4432 - val_acc: 0.3958\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.4698 - acc: 0.3862 - val_loss: 2.5046 - val_acc: 0.3851\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.4501 - acc: 0.3934 - val_loss: 2.3083 - val_acc: 0.4518\n",
      "l1-0.01 l2-0.01 drop-0.2 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 121.9593 - acc: 0.1004 - val_loss: 21.4354 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 6.8147 - acc: 0.1029 - val_loss: 2.8932 - val_acc: 0.1017\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 3.1531 - acc: 0.1084 - val_loss: 2.8923 - val_acc: 0.1008\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.8927 - acc: 0.0979 - val_loss: 2.8935 - val_acc: 0.1001\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.8927 - acc: 0.0993 - val_loss: 2.8935 - val_acc: 0.1008\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.8960 - acc: 0.1055 - val_loss: 2.8923 - val_acc: 0.0997\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.8987 - acc: 0.1002 - val_loss: 2.8927 - val_acc: 0.1002\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.8926 - acc: 0.0996 - val_loss: 2.8924 - val_acc: 0.0989\n",
      "Epoch 00008: early stopping\n",
      "l1-0.01 l2-0 drop-0.2 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 22.2760 - acc: 0.0995 - val_loss: 21.6773 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 21.1464 - acc: 0.1000 - val_loss: 20.6390 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 20.1849 - acc: 0.1000 - val_loss: 19.7510 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 19.3627 - acc: 0.1000 - val_loss: 18.9916 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 18.6595 - acc: 0.1000 - val_loss: 18.3421 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 18.0581 - acc: 0.1000 - val_loss: 17.7867 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 17.5438 - acc: 0.1000 - val_loss: 17.3117 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 17.1040 - acc: 0.1000 - val_loss: 16.9055 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.7279 - acc: 0.1000 - val_loss: 16.5581 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.4061 - acc: 0.1000 - val_loss: 16.2604 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.1371 - acc: 0.0998 - val_loss: 16.0111 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.8997 - acc: 0.1000 - val_loss: 15.7932 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.6980 - acc: 0.1000 - val_loss: 15.6069 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.5254 - acc: 0.1000 - val_loss: 15.4475 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.3778 - acc: 0.1000 - val_loss: 15.3112 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.2516 - acc: 0.1000 - val_loss: 15.1947 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.1437 - acc: 0.1000 - val_loss: 15.0950 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.0514 - acc: 0.1000 - val_loss: 15.0098 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.9725 - acc: 0.1000 - val_loss: 14.9369 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.9050 - acc: 0.1000 - val_loss: 14.8745 - val_acc: 0.1000\n",
      "l1-0 l2-0.01 drop-0.2 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5067 - acc: 0.0997 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00006: early stopping\n",
      "l1-0 l2-0 drop-0.2 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 120.0448 - acc: 0.1001 - val_loss: 18.7024 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 14.2164 - acc: 0.1029 - val_loss: 2.9157 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.9577 - acc: 0.1199 - val_loss: 2.9011 - val_acc: 0.1076\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.9655 - acc: 0.1777 - val_loss: 3.0822 - val_acc: 0.1669\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.8603 - acc: 0.2176 - val_loss: 2.8007 - val_acc: 0.2461\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.8125 - acc: 0.2485 - val_loss: 2.7495 - val_acc: 0.2978\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.7610 - acc: 0.2656 - val_loss: 2.7501 - val_acc: 0.2559\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.7377 - acc: 0.2709 - val_loss: 2.7022 - val_acc: 0.2890\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.7206 - acc: 0.2860 - val_loss: 2.6849 - val_acc: 0.2880\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.7127 - acc: 0.2981 - val_loss: 2.8499 - val_acc: 0.2415\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6833 - acc: 0.3134 - val_loss: 2.6040 - val_acc: 0.3338\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6730 - acc: 0.3221 - val_loss: 2.5866 - val_acc: 0.3639\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6579 - acc: 0.3267 - val_loss: 2.5906 - val_acc: 0.3527\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.6666 - acc: 0.3342 - val_loss: 2.5996 - val_acc: 0.3738\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6611 - acc: 0.3444 - val_loss: 2.5728 - val_acc: 0.3728\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.6566 - acc: 0.3518 - val_loss: 2.5377 - val_acc: 0.3930\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6355 - acc: 0.3601 - val_loss: 2.6649 - val_acc: 0.3649\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6102 - acc: 0.3653 - val_loss: 2.6860 - val_acc: 0.3765\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.6106 - acc: 0.3694 - val_loss: 2.4818 - val_acc: 0.4240\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.5821 - acc: 0.3809 - val_loss: 2.4731 - val_acc: 0.4292\n",
      "l1-0.01 l2-0.01 drop-0.5 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 121.9046 - acc: 0.0998 - val_loss: 21.4099 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 16.6286 - acc: 0.1002 - val_loss: 15.3323 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 16.0441 - acc: 0.1001 - val_loss: 17.1110 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 16.3802 - acc: 0.1013 - val_loss: 15.6032 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.3769 - acc: 0.0986 - val_loss: 15.2255 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.1827 - acc: 0.0996 - val_loss: 15.1403 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.1241 - acc: 0.1000 - val_loss: 15.1127 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 16279.6254 - acc: 0.0986 - val_loss: 466313.2189 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 466298.7757 - acc: 0.1000 - val_loss: 466284.2501 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 466269.8977 - acc: 0.1000 - val_loss: 466255.4064 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 466241.0661 - acc: 0.1000 - val_loss: 466226.6251 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 466212.2785 - acc: 0.1000 - val_loss: 466197.8439 - val_acc: 0.1000\n",
      "Epoch 00012: early stopping\n",
      "l1-0.01 l2-0 drop-0.5 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 22.2292 - acc: 0.1024 - val_loss: 21.6813 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 21.1505 - acc: 0.1000 - val_loss: 20.6432 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 20.1889 - acc: 0.1000 - val_loss: 19.7546 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 19.3661 - acc: 0.1000 - val_loss: 18.9947 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 18.6624 - acc: 0.1000 - val_loss: 18.3448 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 18.0606 - acc: 0.1000 - val_loss: 17.7890 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 17.5460 - acc: 0.1000 - val_loss: 17.3137 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 17.1058 - acc: 0.1000 - val_loss: 16.9072 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.7294 - acc: 0.1000 - val_loss: 16.5595 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.4075 - acc: 0.1000 - val_loss: 16.2622 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 16.1322 - acc: 0.1000 - val_loss: 16.0080 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.8968 - acc: 0.1000 - val_loss: 15.7905 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 15.6954 - acc: 0.1000 - val_loss: 15.6046 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.4445 - acc: 0.1013 - val_loss: 3.2488 - val_acc: 0.1337\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 3.1159 - acc: 0.1656 - val_loss: 3.0982 - val_acc: 0.1307\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.7467 - acc: 0.2859 - val_loss: 2.4699 - val_acc: 0.3692\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.3906 - acc: 0.3791 - val_loss: 2.1773 - val_acc: 0.4582\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1347 - acc: 0.4445 - val_loss: 1.9740 - val_acc: 0.5028\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.9354 - acc: 0.4923 - val_loss: 1.8213 - val_acc: 0.5241\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.8076 - acc: 0.5192 - val_loss: 1.6510 - val_acc: 0.5692\n",
      "l1-0 l2-0.01 drop-0.5 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = SGD with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5045 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00006: early stopping\n",
      "l1-0 l2-0 drop-0.5 opt-SGD do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 22.2847 - acc: 0.1767 - val_loss: 3.4372 - val_acc: 0.2573\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4657 - acc: 0.2781 - val_loss: 3.3589 - val_acc: 0.3561\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.3574 - acc: 0.3346 - val_loss: 3.2660 - val_acc: 0.3680\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.2800 - acc: 0.3610 - val_loss: 3.1816 - val_acc: 0.3861\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.2281 - acc: 0.3860 - val_loss: 3.1872 - val_acc: 0.4153\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.1898 - acc: 0.4026 - val_loss: 3.0664 - val_acc: 0.4596\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.1868 - acc: 0.4323 - val_loss: 3.1425 - val_acc: 0.4720\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.1421 - acc: 0.4591 - val_loss: 2.9554 - val_acc: 0.5166\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.0635 - acc: 0.4915 - val_loss: 2.9902 - val_acc: 0.5391\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.0319 - acc: 0.5250 - val_loss: 2.9048 - val_acc: 0.5598\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.9674 - acc: 0.5406 - val_loss: 2.8149 - val_acc: 0.5988\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.9206 - acc: 0.5522 - val_loss: 2.8375 - val_acc: 0.5968\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8875 - acc: 0.5637 - val_loss: 2.7278 - val_acc: 0.6266\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.8651 - acc: 0.5740 - val_loss: 2.8120 - val_acc: 0.6023\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.8557 - acc: 0.5786 - val_loss: 2.7799 - val_acc: 0.6237\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8238 - acc: 0.5898 - val_loss: 2.6822 - val_acc: 0.6321\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8160 - acc: 0.5997 - val_loss: 2.7614 - val_acc: 0.6306\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7966 - acc: 0.6038 - val_loss: 2.7519 - val_acc: 0.6155\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7802 - acc: 0.6117 - val_loss: 2.7370 - val_acc: 0.6184\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7730 - acc: 0.6125 - val_loss: 2.7961 - val_acc: 0.6117\n",
      "l1-0.01 l2-0.01 drop-0.2 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 24.6825 - acc: 0.2378 - val_loss: 3.4443 - val_acc: 0.3855\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.4003 - acc: 0.3897 - val_loss: 3.1567 - val_acc: 0.4400\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.2022 - acc: 0.4239 - val_loss: 3.1473 - val_acc: 0.4684\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1356 - acc: 0.4596 - val_loss: 2.9615 - val_acc: 0.5222\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 3.0718 - acc: 0.4875 - val_loss: 2.9133 - val_acc: 0.5352\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.9801 - acc: 0.5042 - val_loss: 2.8897 - val_acc: 0.5477\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.9414 - acc: 0.5199 - val_loss: 2.8719 - val_acc: 0.5469\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8957 - acc: 0.5317 - val_loss: 2.8151 - val_acc: 0.5684\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.8798 - acc: 0.5421 - val_loss: 2.8383 - val_acc: 0.5664\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8308 - acc: 0.5537 - val_loss: 2.7730 - val_acc: 0.5723\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8002 - acc: 0.5642 - val_loss: 2.7658 - val_acc: 0.5761\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.8166 - acc: 0.5737 - val_loss: 2.6984 - val_acc: 0.6259\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.7908 - acc: 0.5809 - val_loss: 2.6836 - val_acc: 0.6210\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7729 - acc: 0.5880 - val_loss: 2.6810 - val_acc: 0.6184\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7551 - acc: 0.5928 - val_loss: 2.7677 - val_acc: 0.6063\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.7584 - acc: 0.5941 - val_loss: 2.6677 - val_acc: 0.6416\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7379 - acc: 0.6022 - val_loss: 2.6342 - val_acc: 0.6441\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7218 - acc: 0.6086 - val_loss: 2.6883 - val_acc: 0.6275\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.7083 - acc: 0.6091 - val_loss: 2.6481 - val_acc: 0.6427\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.6995 - acc: 0.6175 - val_loss: 2.6831 - val_acc: 0.6233\n",
      "l1-0.01 l2-0 drop-0.2 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 16.1823 - acc: 0.0999 - val_loss: 14.6846 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5966 - acc: 0.0996 - val_loss: 14.5813 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 11.4525 - acc: 0.0996 - val_loss: 2.4523 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.3427 - acc: 0.0976 - val_loss: 2.3103 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.3061 - acc: 0.0995 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.3033 - acc: 0.0981 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.3035 - acc: 0.1006 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2545 - acc: 0.1321 - val_loss: 2.0991 - val_acc: 0.2015\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.8712 - acc: 0.3121 - val_loss: 1.6532 - val_acc: 0.4198\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.6568 - acc: 0.4163 - val_loss: 1.4959 - val_acc: 0.4841\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.4991 - acc: 0.4911 - val_loss: 1.2973 - val_acc: 0.5723\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3910 - acc: 0.5396 - val_loss: 1.2418 - val_acc: 0.5967\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3049 - acc: 0.5756 - val_loss: 1.1835 - val_acc: 0.6243\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.2402 - acc: 0.6026 - val_loss: 1.1163 - val_acc: 0.6501\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.1883 - acc: 0.6185 - val_loss: 1.0882 - val_acc: 0.6611\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.1535 - acc: 0.6329 - val_loss: 1.0483 - val_acc: 0.6739\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.1229 - acc: 0.6452 - val_loss: 1.0342 - val_acc: 0.6772\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0950 - acc: 0.6513 - val_loss: 1.0460 - val_acc: 0.6696\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0717 - acc: 0.6633 - val_loss: 1.0505 - val_acc: 0.6723\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.0535 - acc: 0.6689 - val_loss: 0.9806 - val_acc: 0.6992\n",
      "l1-0 l2-0.01 drop-0.2 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5046 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00006: early stopping\n",
      "l1-0 l2-0 drop-0.2 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 34.5235 - acc: 0.1060 - val_loss: 3.8240 - val_acc: 0.1924\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4814 - acc: 0.2253 - val_loss: 3.3049 - val_acc: 0.2694\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4381 - acc: 0.2614 - val_loss: 3.4481 - val_acc: 0.3281\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4716 - acc: 0.3088 - val_loss: 3.3198 - val_acc: 0.3792\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.4576 - acc: 0.3333 - val_loss: 3.4556 - val_acc: 0.3854\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.5900 - acc: 0.3739 - val_loss: 3.5056 - val_acc: 0.4190\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 3.5171 - acc: 0.4020 - val_loss: 3.4657 - val_acc: 0.4391\n",
      "Epoch 00007: early stopping\n",
      "l1-0.01 l2-0.01 drop-0.5 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.010000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 29.0110 - acc: 0.1533 - val_loss: 3.4662 - val_acc: 0.2626\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.5336 - acc: 0.2750 - val_loss: 3.5358 - val_acc: 0.3587\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.5645 - acc: 0.3380 - val_loss: 3.4355 - val_acc: 0.4182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.5055 - acc: 0.3773 - val_loss: 3.4050 - val_acc: 0.4093\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.4096 - acc: 0.4015 - val_loss: 3.3575 - val_acc: 0.4466\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.3860 - acc: 0.4180 - val_loss: 3.3144 - val_acc: 0.4489\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.3801 - acc: 0.4407 - val_loss: 3.2393 - val_acc: 0.5032\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.3523 - acc: 0.4544 - val_loss: 3.2347 - val_acc: 0.5192\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.3198 - acc: 0.4676 - val_loss: 3.1869 - val_acc: 0.5254\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.2911 - acc: 0.4807 - val_loss: 3.1181 - val_acc: 0.5513\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.2554 - acc: 0.4985 - val_loss: 3.0896 - val_acc: 0.5490\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.2336 - acc: 0.5051 - val_loss: 3.1606 - val_acc: 0.5340\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1777 - acc: 0.5177 - val_loss: 3.0104 - val_acc: 0.5615\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1494 - acc: 0.5248 - val_loss: 3.0174 - val_acc: 0.5834\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1449 - acc: 0.5302 - val_loss: 3.0022 - val_acc: 0.5870\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1192 - acc: 0.5409 - val_loss: 3.0372 - val_acc: 0.5845\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1323 - acc: 0.5440 - val_loss: 3.0203 - val_acc: 0.5953\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1140 - acc: 0.5466 - val_loss: 2.9789 - val_acc: 0.5852\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.0837 - acc: 0.5568 - val_loss: 2.9653 - val_acc: 0.6159\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 3.1107 - acc: 0.5562 - val_loss: 3.0698 - val_acc: 0.5870\n",
      "l1-0.01 l2-0 drop-0.5 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.010000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 16.6876 - acc: 0.1003 - val_loss: 14.9602 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.7862 - acc: 0.1001 - val_loss: 14.6310 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5634 - acc: 0.1001 - val_loss: 14.5282 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5282 - acc: 0.1000 - val_loss: 14.6502 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5941 - acc: 0.1000 - val_loss: 14.5431 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5248 - acc: 0.1000 - val_loss: 14.5142 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5105 - acc: 0.1000 - val_loss: 14.5081 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 8.5394 - acc: 0.1029 - val_loss: 2.3405 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3175 - acc: 0.0990 - val_loss: 2.3074 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3052 - acc: 0.0974 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3033 - acc: 0.0979 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3028 - acc: 0.1002 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3028 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0962 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.1003 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0991 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0995 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0983 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "l1-0 l2-0.01 drop-0.5 opt-Adam do_nb-False\n",
      "Experiment with regulizer_ratio1 = 0.000000  regulizer_ratio2 = 0.000000 drop ratio = 0 optimizer = Adam with normalize = False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 14.5056 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00006: early stopping\n",
      "l1-0 l2-0 drop-0.5 opt-Adam do_nb-False\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for do_nb in do_NB:\n",
    "    for opt in OPTIMIZER:\n",
    "        for drop in Dropout_EXP:\n",
    "            for l1 in L1_EXP:\n",
    "                for l2 in L2_EXP:\n",
    "                    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "                    print(\"Experiment with regulizer_ratio1 = %.6f  regulizer_ratio2 = %.6f drop ratio = %.f optimizer = %s with normalize = %s\" % (l1,l2,drop,opt,do_nb))\n",
    "                    model = build_mlp_CNN(input_shape=x_train.shape[1:], output_units=10,ratio=l1,ratio2=l2,drop_r=drop,do_NB = do_nb)\n",
    "                    model.summary()\n",
    "                    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=opt)\n",
    "\n",
    "                    model.fit(x_train, y_train, \n",
    "                              epochs=EPOCHS, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              validation_data=(x_test, y_test), \n",
    "                              shuffle=True,\n",
    "                             callbacks=[earlystop])\n",
    "\n",
    "                    # Collect results\n",
    "                    train_loss = model.history.history[\"loss\"]\n",
    "                    valid_loss = model.history.history[\"val_loss\"]\n",
    "                    train_acc = model.history.history[\"acc\"]\n",
    "                    valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "                    exp_name_tag = \"l1-%s l2-%s drop-%s opt-%s do_nb-%s\" % (str(l1),str(l2),drop,opt,do_nb)\n",
    "                    print(exp_name_tag)\n",
    "                    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                             'valid-loss': valid_loss,\n",
    "                                             'train-acc': train_acc,\n",
    "                                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l1-0 l2-0 drop-0.5 opt-Adam do_nb-False'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-96cbd6880857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w','C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9','tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
