{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "* 學習如何在 keras 中加入 reduce learning rate\n",
    "* 知道如何設定 reduce_lr 的監控目標\n",
    "* 比較使用有無使用 reduce_lr 時的 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 載入 Callbacks, 並設定監控目標為 validation loss\n",
    "\"\"\"\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience=5, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 2.2087 - acc: 0.2701 - val_loss: 2.0695 - val_acc: 0.3201\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.7404 - acc: 0.3954 - val_loss: 1.8268 - val_acc: 0.3724\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.6115 - acc: 0.4403 - val_loss: 1.6813 - val_acc: 0.4107\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.5399 - acc: 0.4625 - val_loss: 1.6229 - val_acc: 0.4319\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.4845 - acc: 0.4820 - val_loss: 1.5857 - val_acc: 0.4431\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.4390 - acc: 0.4987 - val_loss: 1.5436 - val_acc: 0.4545\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.3992 - acc: 0.5117 - val_loss: 1.5390 - val_acc: 0.4541\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.3641 - acc: 0.5257 - val_loss: 1.5282 - val_acc: 0.4635\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3326 - acc: 0.5372 - val_loss: 1.4987 - val_acc: 0.4700\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3030 - acc: 0.5486 - val_loss: 1.4955 - val_acc: 0.4717\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2751 - acc: 0.5593 - val_loss: 1.4799 - val_acc: 0.4761\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.2483 - acc: 0.5700 - val_loss: 1.5082 - val_acc: 0.4656\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2229 - acc: 0.5779 - val_loss: 1.4709 - val_acc: 0.4816\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.1969 - acc: 0.5886 - val_loss: 1.4578 - val_acc: 0.4843\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.1731 - acc: 0.5961 - val_loss: 1.4564 - val_acc: 0.4880\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.1506 - acc: 0.6065 - val_loss: 1.4503 - val_acc: 0.4880\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.1276 - acc: 0.6139 - val_loss: 1.4434 - val_acc: 0.4913\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.1053 - acc: 0.6221 - val_loss: 1.4471 - val_acc: 0.4909\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.0837 - acc: 0.6321 - val_loss: 1.4414 - val_acc: 0.4958\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.0632 - acc: 0.6400 - val_loss: 1.4486 - val_acc: 0.4908\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True,\n",
    "          callbacks=[reduce_lr]\n",
    "         )\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請改變 reduce_lr 的 patience 和 factor 並比較不同設定下，對訓練/驗證集的影響\n",
    "2. 請將 optimizer 換成 Adam、RMSprop 搭配 reduce_lr 並比較訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 25 # IF you feel too run to finish, try to make it smaller\n",
    "BATCH_SIZE = 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "optimizer_set = [keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=0.95),\n",
    "                 keras.optimizers.Adam(lr=LEARNING_RATE),\n",
    "                 keras.optimizers.RMSprop(lr=LEARNING_RATE)]\n",
    "\n",
    "\"\"\"Code Here\n",
    "建立實驗的比較組合\n",
    "\"\"\"\n",
    "reduce_lr_factor = [0.1,0.01,0.001,0.0001]\n",
    "redice_lr_patient = [3,10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, reduce_factor: 0.10, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.2192 - acc: 0.2657 - val_loss: 2.1194 - val_acc: 0.3237\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.7403 - acc: 0.3911 - val_loss: 1.8656 - val_acc: 0.3731\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.6187 - acc: 0.4319 - val_loss: 1.6878 - val_acc: 0.4150\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5452 - acc: 0.4593 - val_loss: 1.6227 - val_acc: 0.4345\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.4924 - acc: 0.4789 - val_loss: 1.5814 - val_acc: 0.4430\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.4473 - acc: 0.4934 - val_loss: 1.5679 - val_acc: 0.4504\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.4087 - acc: 0.5079 - val_loss: 1.5425 - val_acc: 0.4550\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.3731 - acc: 0.5208 - val_loss: 1.5205 - val_acc: 0.4674\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3432 - acc: 0.5313 - val_loss: 1.5238 - val_acc: 0.4612\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3158 - acc: 0.5439 - val_loss: 1.5154 - val_acc: 0.4680\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2904 - acc: 0.5523 - val_loss: 1.4964 - val_acc: 0.4707\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.2616 - acc: 0.5611 - val_loss: 1.4878 - val_acc: 0.4712\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.2376 - acc: 0.5693 - val_loss: 1.4721 - val_acc: 0.4786\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2133 - acc: 0.5796 - val_loss: 1.4687 - val_acc: 0.4800\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.1880 - acc: 0.5883 - val_loss: 1.4793 - val_acc: 0.4817\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1660 - acc: 0.5972 - val_loss: 1.4627 - val_acc: 0.4865\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.1441 - acc: 0.6061 - val_loss: 1.4564 - val_acc: 0.4914\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1229 - acc: 0.6129 - val_loss: 1.4477 - val_acc: 0.4898\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.0984 - acc: 0.6220 - val_loss: 1.4530 - val_acc: 0.4939\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.0790 - acc: 0.6308 - val_loss: 1.4499 - val_acc: 0.4901\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.0574 - acc: 0.6382 - val_loss: 1.4587 - val_acc: 0.4948\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0364 - acc: 0.6465 - val_loss: 1.4572 - val_acc: 0.4921\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0151 - acc: 0.6556 - val_loss: 1.4446 - val_acc: 0.4992\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.9940 - acc: 0.6642 - val_loss: 1.4576 - val_acc: 0.4907\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.9740 - acc: 0.6722 - val_loss: 1.4539 - val_acc: 0.4955\n",
      "Numbers of exp: 1, reduce_factor: 0.10, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 2.2023 - acc: 0.2774 - val_loss: 2.1097 - val_acc: 0.3095\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.7413 - acc: 0.3956 - val_loss: 1.8359 - val_acc: 0.3693\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.6157 - acc: 0.4359 - val_loss: 1.7006 - val_acc: 0.4059\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.5417 - acc: 0.4608 - val_loss: 1.6585 - val_acc: 0.4168\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.4866 - acc: 0.4822 - val_loss: 1.5960 - val_acc: 0.4370\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.4422 - acc: 0.4972 - val_loss: 1.5726 - val_acc: 0.4468\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.4022 - acc: 0.5130 - val_loss: 1.5523 - val_acc: 0.4547\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3656 - acc: 0.5261 - val_loss: 1.5352 - val_acc: 0.4585\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.3351 - acc: 0.5359 - val_loss: 1.5285 - val_acc: 0.4640\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.3034 - acc: 0.5492 - val_loss: 1.5112 - val_acc: 0.4660\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.2754 - acc: 0.5595 - val_loss: 1.5047 - val_acc: 0.4724\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.2484 - acc: 0.5683 - val_loss: 1.4924 - val_acc: 0.4773\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2249 - acc: 0.5777 - val_loss: 1.4920 - val_acc: 0.4790\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2006 - acc: 0.5853 - val_loss: 1.4753 - val_acc: 0.4820\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.1758 - acc: 0.5953 - val_loss: 1.4784 - val_acc: 0.4846\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1500 - acc: 0.6061 - val_loss: 1.4631 - val_acc: 0.4894\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1280 - acc: 0.6151 - val_loss: 1.4701 - val_acc: 0.4883\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1061 - acc: 0.6220 - val_loss: 1.4625 - val_acc: 0.4882\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.0829 - acc: 0.6308 - val_loss: 1.4752 - val_acc: 0.4875\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0629 - acc: 0.6397 - val_loss: 1.4639 - val_acc: 0.4920\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.0409 - acc: 0.6470 - val_loss: 1.4645 - val_acc: 0.4922\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.0189 - acc: 0.6576 - val_loss: 1.4576 - val_acc: 0.4981\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.0003 - acc: 0.6634 - val_loss: 1.4678 - val_acc: 0.4932\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.9790 - acc: 0.6738 - val_loss: 1.4752 - val_acc: 0.4914 - loss: 0.9789 - acc: 0.674\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.9577 - acc: 0.6800 - val_loss: 1.4985 - val_acc: 0.4875\n",
      "Numbers of exp: 2, reduce_factor: 0.10, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 2.2100 - acc: 0.2668 - val_loss: 2.0830 - val_acc: 0.3164\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.7375 - acc: 0.3956 - val_loss: 1.8166 - val_acc: 0.3792\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.6135 - acc: 0.4362 - val_loss: 1.6798 - val_acc: 0.4145\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.5386 - acc: 0.4616 - val_loss: 1.6227 - val_acc: 0.4338\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.4826 - acc: 0.4818 - val_loss: 1.5872 - val_acc: 0.4439\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.4391 - acc: 0.4979 - val_loss: 1.5615 - val_acc: 0.4515\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.4005 - acc: 0.5111 - val_loss: 1.5551 - val_acc: 0.4508\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.3666 - acc: 0.5229 - val_loss: 1.5356 - val_acc: 0.4587\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.3341 - acc: 0.5361 - val_loss: 1.5080 - val_acc: 0.4684\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.3050 - acc: 0.5472 - val_loss: 1.5090 - val_acc: 0.4751\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2770 - acc: 0.5582 - val_loss: 1.4934 - val_acc: 0.4787\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2503 - acc: 0.5660 - val_loss: 1.4785 - val_acc: 0.4788\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.2259 - acc: 0.5773 - val_loss: 1.4824 - val_acc: 0.4775\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.1995 - acc: 0.5876 - val_loss: 1.4714 - val_acc: 0.4788\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1774 - acc: 0.5957 - val_loss: 1.4724 - val_acc: 0.4815\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1537 - acc: 0.6053 - val_loss: 1.4670 - val_acc: 0.4799\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.1319 - acc: 0.6139 - val_loss: 1.4598 - val_acc: 0.4901\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1079 - acc: 0.6244 - val_loss: 1.4551 - val_acc: 0.4950acc:  - ETA: 1s - loss: 1.1050 - ac\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.0862 - acc: 0.6305 - val_loss: 1.4525 - val_acc: 0.4933\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.0647 - acc: 0.6373 - val_loss: 1.4573 - val_acc: 0.4913\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.0450 - acc: 0.6457 - val_loss: 1.4554 - val_acc: 0.4916\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.0223 - acc: 0.6556 - val_loss: 1.4557 - val_acc: 0.4948\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.0028 - acc: 0.6621 - val_loss: 1.4634 - val_acc: 0.4939\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.9803 - acc: 0.6708 - val_loss: 1.4541 - val_acc: 0.4961\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.9628 - acc: 0.6776 - val_loss: 1.4629 - val_acc: 0.4907\n",
      "Numbers of exp: 3, reduce_factor: 0.01, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 2.2215 - acc: 0.2712 - val_loss: 2.1009 - val_acc: 0.3332\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.7519 - acc: 0.3908 - val_loss: 1.8105 - val_acc: 0.3844\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.6252 - acc: 0.4295 - val_loss: 1.7253 - val_acc: 0.4108\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.5477 - acc: 0.4590 - val_loss: 1.6421 - val_acc: 0.4271\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.4913 - acc: 0.4780 - val_loss: 1.6001 - val_acc: 0.4404\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.4446 - acc: 0.4955 - val_loss: 1.5663 - val_acc: 0.4455\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4034 - acc: 0.5108 - val_loss: 1.5527 - val_acc: 0.4502\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.3696 - acc: 0.5244 - val_loss: 1.5329 - val_acc: 0.4584\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.3344 - acc: 0.5376 - val_loss: 1.5219 - val_acc: 0.4634\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.3060 - acc: 0.5467 - val_loss: 1.5067 - val_acc: 0.4703\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.2758 - acc: 0.5584 - val_loss: 1.4929 - val_acc: 0.4723\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.2504 - acc: 0.5669 - val_loss: 1.4835 - val_acc: 0.4759\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.2237 - acc: 0.5786 - val_loss: 1.4785 - val_acc: 0.4795\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.1977 - acc: 0.5884 - val_loss: 1.4703 - val_acc: 0.4797\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.1764 - acc: 0.5966 - val_loss: 1.4644 - val_acc: 0.4856\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.1496 - acc: 0.6062 - val_loss: 1.4651 - val_acc: 0.4824\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1279 - acc: 0.6145 - val_loss: 1.4572 - val_acc: 0.4852\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1042 - acc: 0.6236 - val_loss: 1.4660 - val_acc: 0.4812\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.0827 - acc: 0.6333 - val_loss: 1.4516 - val_acc: 0.4883\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.0597 - acc: 0.6399 - val_loss: 1.4504 - val_acc: 0.4927\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.0382 - acc: 0.6495 - val_loss: 1.4475 - val_acc: 0.4929\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.0168 - acc: 0.6563 - val_loss: 1.4527 - val_acc: 0.4918\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.9955 - acc: 0.6642 - val_loss: 1.4533 - val_acc: 0.4910\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.9760 - acc: 0.6719 - val_loss: 1.4504 - val_acc: 0.4985\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.9559 - acc: 0.6798 - val_loss: 1.4569 - val_acc: 0.4922\n",
      "Numbers of exp: 4, reduce_factor: 0.01, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.2308 - acc: 0.2690 - val_loss: 2.1648 - val_acc: 0.3104\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.7447 - acc: 0.3910 - val_loss: 1.8269 - val_acc: 0.3732\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.6209 - acc: 0.4322 - val_loss: 1.6917 - val_acc: 0.4125\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.5511 - acc: 0.4589 - val_loss: 1.6443 - val_acc: 0.4217\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.4951 - acc: 0.4774 - val_loss: 1.6089 - val_acc: 0.4405\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.4510 - acc: 0.4948 - val_loss: 1.5901 - val_acc: 0.4405\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.4150 - acc: 0.5078 - val_loss: 1.5661 - val_acc: 0.4527\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.3817 - acc: 0.5179 - val_loss: 1.5510 - val_acc: 0.4589\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.3508 - acc: 0.5295 - val_loss: 1.5535 - val_acc: 0.4546ss: 1.3505 -\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.3206 - acc: 0.5405 - val_loss: 1.5376 - val_acc: 0.4610\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2926 - acc: 0.5520 - val_loss: 1.5080 - val_acc: 0.4725\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2684 - acc: 0.5611 - val_loss: 1.4975 - val_acc: 0.4740\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2406 - acc: 0.5721 - val_loss: 1.4961 - val_acc: 0.4800\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2174 - acc: 0.5798 - val_loss: 1.5025 - val_acc: 0.4804\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1926 - acc: 0.5890 - val_loss: 1.4908 - val_acc: 0.4783\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1696 - acc: 0.5959 - val_loss: 1.4790 - val_acc: 0.4818\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.1438 - acc: 0.6078 - val_loss: 1.4782 - val_acc: 0.4867\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 1.1220 - acc: 0.6145 - val_loss: 1.4759 - val_acc: 0.4841\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.1007 - acc: 0.6253 - val_loss: 1.4795 - val_acc: 0.4916\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0784 - acc: 0.6327 - val_loss: 1.4780 - val_acc: 0.4856\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.0563 - acc: 0.6413 - val_loss: 1.4778 - val_acc: 0.4886\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.0352 - acc: 0.6477 - val_loss: 1.4770 - val_acc: 0.4854\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.0158 - acc: 0.6564 - val_loss: 1.4787 - val_acc: 0.4932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.9942 - acc: 0.6647 - val_loss: 1.4740 - val_acc: 0.4899\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.9713 - acc: 0.6745 - val_loss: 1.4840 - val_acc: 0.4898\n",
      "Numbers of exp: 5, reduce_factor: 0.01, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 2.2065 - acc: 0.2729 - val_loss: 2.1092 - val_acc: 0.3119\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.7360 - acc: 0.3948 - val_loss: 1.8171 - val_acc: 0.3764\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6121 - acc: 0.4366 - val_loss: 1.7239 - val_acc: 0.4027\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.5408 - acc: 0.4606 - val_loss: 1.6382 - val_acc: 0.4332\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.4848 - acc: 0.4803 - val_loss: 1.5846 - val_acc: 0.4473\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.4391 - acc: 0.4955 - val_loss: 1.5521 - val_acc: 0.4573\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.4012 - acc: 0.5092 - val_loss: 1.5466 - val_acc: 0.4539\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.3674 - acc: 0.5220 - val_loss: 1.5276 - val_acc: 0.4632\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.3362 - acc: 0.5333 - val_loss: 1.5057 - val_acc: 0.4716\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3057 - acc: 0.5454 - val_loss: 1.4931 - val_acc: 0.4760\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.2777 - acc: 0.5559 - val_loss: 1.4859 - val_acc: 0.4772\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2527 - acc: 0.5658 - val_loss: 1.4659 - val_acc: 0.4881\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.2269 - acc: 0.5768 - val_loss: 1.4707 - val_acc: 0.4834\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2008 - acc: 0.5854 - val_loss: 1.4643 - val_acc: 0.4874\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1779 - acc: 0.5937 - val_loss: 1.4551 - val_acc: 0.4892\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1539 - acc: 0.6033 - val_loss: 1.4626 - val_acc: 0.4854 loss: 1.1499 -\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.1309 - acc: 0.6126 - val_loss: 1.4585 - val_acc: 0.4927\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1106 - acc: 0.6210 - val_loss: 1.4467 - val_acc: 0.4930\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.0877 - acc: 0.6279 - val_loss: 1.4695 - val_acc: 0.4893\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0651 - acc: 0.6368 - val_loss: 1.4441 - val_acc: 0.4987\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0442 - acc: 0.6447 - val_loss: 1.4419 - val_acc: 0.4969\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.0219 - acc: 0.6563 - val_loss: 1.4404 - val_acc: 0.5006\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.0011 - acc: 0.6603 - val_loss: 1.4505 - val_acc: 0.5008\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.9806 - acc: 0.6702 - val_loss: 1.4498 - val_acc: 0.4984\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.9602 - acc: 0.6772 - val_loss: 1.4547 - val_acc: 0.5005\n",
      "Numbers of exp: 6, reduce_factor: 0.00, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 2.2158 - acc: 0.2666 - val_loss: 2.0899 - val_acc: 0.3305\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7458 - acc: 0.3906 - val_loss: 1.7993 - val_acc: 0.3869\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.6180 - acc: 0.4340 - val_loss: 1.6762 - val_acc: 0.4169\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.5418 - acc: 0.4602 - val_loss: 1.6293 - val_acc: 0.4314\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.4860 - acc: 0.4783 - val_loss: 1.5878 - val_acc: 0.4445\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.4388 - acc: 0.4959 - val_loss: 1.5521 - val_acc: 0.4542\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.3992 - acc: 0.5125 - val_loss: 1.5385 - val_acc: 0.4642\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3661 - acc: 0.5232 - val_loss: 1.5286 - val_acc: 0.4637\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3350 - acc: 0.5344 - val_loss: 1.5051 - val_acc: 0.4711\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.3052 - acc: 0.5468 - val_loss: 1.4915 - val_acc: 0.4799\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.2767 - acc: 0.5579 - val_loss: 1.4995 - val_acc: 0.4705\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.2500 - acc: 0.5654 - val_loss: 1.4828 - val_acc: 0.4764\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.2244 - acc: 0.5767 - val_loss: 1.4768 - val_acc: 0.4804\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.1984 - acc: 0.5839 - val_loss: 1.4661 - val_acc: 0.4861\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1765 - acc: 0.5934 - val_loss: 1.4790 - val_acc: 0.4767oss: 1.1 - ETA: 0s - loss: 1.1744 - acc: 0.5\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1532 - acc: 0.6024 - val_loss: 1.4626 - val_acc: 0.4841\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1308 - acc: 0.6116 - val_loss: 1.4552 - val_acc: 0.4904\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.1065 - acc: 0.6208 - val_loss: 1.4464 - val_acc: 0.4918\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.0838 - acc: 0.6305 - val_loss: 1.4435 - val_acc: 0.4927\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.0649 - acc: 0.6367 - val_loss: 1.4454 - val_acc: 0.4958\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.0418 - acc: 0.6439 - val_loss: 1.4577 - val_acc: 0.4918\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.0207 - acc: 0.6516 - val_loss: 1.4525 - val_acc: 0.4946\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.0020 - acc: 0.6589 - val_loss: 1.4520 - val_acc: 0.4965\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.9808 - acc: 0.6687 - val_loss: 1.4501 - val_acc: 0.4996\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.9608 - acc: 0.6748 - val_loss: 1.4724 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Numbers of exp: 7, reduce_factor: 0.00, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 2.1963 - acc: 0.2750 - val_loss: 2.1362 - val_acc: 0.3125\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.7461 - acc: 0.3902 - val_loss: 1.8081 - val_acc: 0.3817\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.6233 - acc: 0.4326 - val_loss: 1.6939 - val_acc: 0.4118\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5510 - acc: 0.4591 - val_loss: 1.6343 - val_acc: 0.4318\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.4958 - acc: 0.4763 - val_loss: 1.5939 - val_acc: 0.4427\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.4516 - acc: 0.4939 - val_loss: 1.5637 - val_acc: 0.4490\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.4111 - acc: 0.5096 - val_loss: 1.5400 - val_acc: 0.4578\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.3761 - acc: 0.5210 - val_loss: 1.5291 - val_acc: 0.4624\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.3442 - acc: 0.5320 - val_loss: 1.5093 - val_acc: 0.4666\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3141 - acc: 0.5435 - val_loss: 1.4918 - val_acc: 0.4721\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2844 - acc: 0.5541 - val_loss: 1.4833 - val_acc: 0.4748\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.2585 - acc: 0.5634 - val_loss: 1.4902 - val_acc: 0.4765\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2341 - acc: 0.5730 - val_loss: 1.4658 - val_acc: 0.4842\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2100 - acc: 0.5811 - val_loss: 1.4567 - val_acc: 0.4880\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.1851 - acc: 0.5901 - val_loss: 1.4637 - val_acc: 0.4821\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1631 - acc: 0.5998 - val_loss: 1.4541 - val_acc: 0.4871\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.1395 - acc: 0.6087 - val_loss: 1.4558 - val_acc: 0.4873\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.1175 - acc: 0.6156 - val_loss: 1.4563 - val_acc: 0.4894\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.0956 - acc: 0.6267 - val_loss: 1.4502 - val_acc: 0.4883\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.0740 - acc: 0.6350 - val_loss: 1.4537 - val_acc: 0.4937\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.0527 - acc: 0.6412 - val_loss: 1.4410 - val_acc: 0.4958\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.0317 - acc: 0.6495 - val_loss: 1.4608 - val_acc: 0.4932\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.0106 - acc: 0.6580 - val_loss: 1.4594 - val_acc: 0.4939\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.9898 - acc: 0.6668 - val_loss: 1.4568 - val_acc: 0.4961\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.9681 - acc: 0.6747 - val_loss: 1.4542 - val_acc: 0.4933\n",
      "Numbers of exp: 8, reduce_factor: 0.00, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 2.2329 - acc: 0.2688 - val_loss: 2.1316 - val_acc: 0.3151\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.7316 - acc: 0.3926 - val_loss: 1.8557 - val_acc: 0.3762\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.6111 - acc: 0.4344 - val_loss: 1.7116 - val_acc: 0.4109\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.5373 - acc: 0.4624 - val_loss: 1.6272 - val_acc: 0.4339\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.4845 - acc: 0.4806 - val_loss: 1.5812 - val_acc: 0.4448\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.4417 - acc: 0.4953 - val_loss: 1.5661 - val_acc: 0.4513\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.4021 - acc: 0.5111 - val_loss: 1.5413 - val_acc: 0.4558\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.3680 - acc: 0.5226 - val_loss: 1.5195 - val_acc: 0.4613\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.3365 - acc: 0.5357 - val_loss: 1.5133 - val_acc: 0.4644\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.3058 - acc: 0.5438 - val_loss: 1.5033 - val_acc: 0.4698\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.2772 - acc: 0.5551 - val_loss: 1.4821 - val_acc: 0.4733\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2498 - acc: 0.5653 - val_loss: 1.4846 - val_acc: 0.4755\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2253 - acc: 0.5736 - val_loss: 1.4780 - val_acc: 0.4811\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.1998 - acc: 0.5838 - val_loss: 1.4758 - val_acc: 0.4766\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.1770 - acc: 0.5935 - val_loss: 1.4603 - val_acc: 0.4857\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.1551 - acc: 0.5999 - val_loss: 1.4642 - val_acc: 0.4834\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 1.1302 - acc: 0.6116 - val_loss: 1.4572 - val_acc: 0.4842\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.1076 - acc: 0.6195 - val_loss: 1.4506 - val_acc: 0.4886\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.0863 - acc: 0.6285 - val_loss: 1.4562 - val_acc: 0.4902\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0645 - acc: 0.6360 - val_loss: 1.4506 - val_acc: 0.4917\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.0443 - acc: 0.6442 - val_loss: 1.4553 - val_acc: 0.4898\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.0212 - acc: 0.6544 - val_loss: 1.4622 - val_acc: 0.4887\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.0025 - acc: 0.6599 - val_loss: 1.4578 - val_acc: 0.4906\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.9797 - acc: 0.6696 - val_loss: 1.4545 - val_acc: 0.4935\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.9588 - acc: 0.6779 - val_loss: 1.4588 - val_acc: 0.4921\n",
      "Numbers of exp: 9, reduce_factor: 0.00, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 2.2094 - acc: 0.2752 - val_loss: 2.1881 - val_acc: 0.3200\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7317 - acc: 0.3968 - val_loss: 1.8985 - val_acc: 0.3566\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.6064 - acc: 0.4379 - val_loss: 1.6902 - val_acc: 0.4103\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.5314 - acc: 0.4621 - val_loss: 1.6378 - val_acc: 0.4272\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4742 - acc: 0.4851 - val_loss: 1.5747 - val_acc: 0.4505\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.4273 - acc: 0.5018 - val_loss: 1.5706 - val_acc: 0.4487\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.3910 - acc: 0.5145 - val_loss: 1.5315 - val_acc: 0.4569\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.3556 - acc: 0.5284 - val_loss: 1.5231 - val_acc: 0.4658\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.3234 - acc: 0.5409 - val_loss: 1.5020 - val_acc: 0.4716\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2945 - acc: 0.5506 - val_loss: 1.4967 - val_acc: 0.4699\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.2664 - acc: 0.5621 - val_loss: 1.4865 - val_acc: 0.4755\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2387 - acc: 0.5725 - val_loss: 1.4776 - val_acc: 0.4831\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2134 - acc: 0.5797 - val_loss: 1.4800 - val_acc: 0.4815\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.1892 - acc: 0.5922 - val_loss: 1.4623 - val_acc: 0.4830\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1655 - acc: 0.5974 - val_loss: 1.4682 - val_acc: 0.4817\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1417 - acc: 0.6088 - val_loss: 1.4738 - val_acc: 0.4863\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.1200 - acc: 0.6157 - val_loss: 1.4477 - val_acc: 0.4928\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0960 - acc: 0.6251 - val_loss: 1.4417 - val_acc: 0.4913\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.0748 - acc: 0.6340 - val_loss: 1.4441 - val_acc: 0.4934\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.0517 - acc: 0.6418 - val_loss: 1.4556 - val_acc: 0.4919\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.0323 - acc: 0.6503 - val_loss: 1.4516 - val_acc: 0.4985\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.0038 - acc: 0.6612 - val_loss: 1.4400 - val_acc: 0.4968\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.9869 - acc: 0.6693 - val_loss: 1.4389 - val_acc: 0.4996\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.9738 - acc: 0.6744 - val_loss: 1.4412 - val_acc: 0.4985\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.9624 - acc: 0.6796 - val_loss: 1.4403 - val_acc: 0.4999\n",
      "Numbers of exp: 10, reduce_factor: 0.00, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 2.3705 - acc: 0.2362 - val_loss: 2.1828 - val_acc: 0.2994\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.8648 - acc: 0.3591 - val_loss: 1.9399 - val_acc: 0.3524\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7281 - acc: 0.3974 - val_loss: 1.8003 - val_acc: 0.3773\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6511 - acc: 0.4232 - val_loss: 1.7410 - val_acc: 0.4014\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5955 - acc: 0.4437 - val_loss: 1.6916 - val_acc: 0.4090\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.5516 - acc: 0.4590 - val_loss: 1.6619 - val_acc: 0.4214\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.5143 - acc: 0.4733 - val_loss: 1.6354 - val_acc: 0.4316\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4835 - acc: 0.4848 - val_loss: 1.6206 - val_acc: 0.4382\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.4538 - acc: 0.4960 - val_loss: 1.5950 - val_acc: 0.4457\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.4286 - acc: 0.5053 - val_loss: 1.5842 - val_acc: 0.4445\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.4043 - acc: 0.5122 - val_loss: 1.5681 - val_acc: 0.4499\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.3827 - acc: 0.5196 - val_loss: 1.5557 - val_acc: 0.4568\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3615 - acc: 0.5290 - val_loss: 1.5554 - val_acc: 0.4608\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.3419 - acc: 0.5349 - val_loss: 1.5390 - val_acc: 0.4592\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3236 - acc: 0.5417 - val_loss: 1.5307 - val_acc: 0.4624\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.3064 - acc: 0.5478 - val_loss: 1.5328 - val_acc: 0.4661\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2894 - acc: 0.5532 - val_loss: 1.5221 - val_acc: 0.4674\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2715 - acc: 0.5607 - val_loss: 1.5163 - val_acc: 0.4676\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2553 - acc: 0.5659 - val_loss: 1.5088 - val_acc: 0.4707\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2404 - acc: 0.5718 - val_loss: 1.5039 - val_acc: 0.4719\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2245 - acc: 0.5782 - val_loss: 1.4963 - val_acc: 0.4759\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2087 - acc: 0.5841 - val_loss: 1.4963 - val_acc: 0.4777\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1945 - acc: 0.5881 - val_loss: 1.4930 - val_acc: 0.4787\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.1807 - acc: 0.5934 - val_loss: 1.4887 - val_acc: 0.4803\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1666 - acc: 0.5991 - val_loss: 1.4873 - val_acc: 0.4829\n",
      "Numbers of exp: 11, reduce_factor: 0.00, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 2.3631 - acc: 0.2352 - val_loss: 2.1703 - val_acc: 0.2862\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.8703 - acc: 0.3523 - val_loss: 1.8876 - val_acc: 0.3618\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.7314 - acc: 0.3951 - val_loss: 1.7875 - val_acc: 0.3811\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6560 - acc: 0.4221 - val_loss: 1.7340 - val_acc: 0.3987\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.6040 - acc: 0.4382 - val_loss: 1.6804 - val_acc: 0.4143\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.5607 - acc: 0.4539 - val_loss: 1.6493 - val_acc: 0.4238\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.5252 - acc: 0.4674 - val_loss: 1.6268 - val_acc: 0.4344\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.4933 - acc: 0.4789 - val_loss: 1.6046 - val_acc: 0.4400\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.4656 - acc: 0.4892 - val_loss: 1.5904 - val_acc: 0.4490\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.4404 - acc: 0.4978 - val_loss: 1.5759 - val_acc: 0.4548\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.4167 - acc: 0.5071 - val_loss: 1.5685 - val_acc: 0.4548\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.3952 - acc: 0.5152 - val_loss: 1.5629 - val_acc: 0.4541\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.3751 - acc: 0.5218 - val_loss: 1.5471 - val_acc: 0.4594\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3555 - acc: 0.5307 - val_loss: 1.5439 - val_acc: 0.4570\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.3374 - acc: 0.5374 - val_loss: 1.5290 - val_acc: 0.4672\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3198 - acc: 0.5422 - val_loss: 1.5178 - val_acc: 0.4701\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.3026 - acc: 0.5494 - val_loss: 1.5191 - val_acc: 0.4695\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.2867 - acc: 0.5545 - val_loss: 1.5204 - val_acc: 0.4674\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2713 - acc: 0.5612 - val_loss: 1.5076 - val_acc: 0.4746\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2547 - acc: 0.5681 - val_loss: 1.5037 - val_acc: 0.4742\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.2395 - acc: 0.5742 - val_loss: 1.4970 - val_acc: 0.4792\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.2254 - acc: 0.5789 - val_loss: 1.4950 - val_acc: 0.4800\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2109 - acc: 0.5850 - val_loss: 1.4915 - val_acc: 0.4818\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1970 - acc: 0.5897 - val_loss: 1.4872 - val_acc: 0.4810\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1822 - acc: 0.5952 - val_loss: 1.4853 - val_acc: 0.4866\n",
      "Numbers of exp: 12, reduce_factor: 0.10, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.7771 - acc: 0.3828 - val_loss: 2.0115 - val_acc: 0.3538\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.5006 - acc: 0.4720 - val_loss: 2.1603 - val_acc: 0.2970\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.4024 - acc: 0.5088 - val_loss: 1.9483 - val_acc: 0.3478\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.3288 - acc: 0.5322 - val_loss: 1.8317 - val_acc: 0.3697\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.2627 - acc: 0.5560 - val_loss: 2.0076 - val_acc: 0.3522\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.2117 - acc: 0.5716 - val_loss: 1.9507 - val_acc: 0.3517\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.1559 - acc: 0.5943 - val_loss: 1.7511 - val_acc: 0.4000\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.1057 - acc: 0.6104 - val_loss: 1.9016 - val_acc: 0.3406\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.0622 - acc: 0.6293 - val_loss: 1.9986 - val_acc: 0.3730\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.0332 - acc: 0.6369 - val_loss: 1.8767 - val_acc: 0.3748\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.9855 - acc: 0.6531 - val_loss: 1.9173 - val_acc: 0.3894\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.9433 - acc: 0.6696 - val_loss: 1.7669 - val_acc: 0.4305\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.9038 - acc: 0.6830 - val_loss: 1.7479 - val_acc: 0.4261\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.8664 - acc: 0.6960 - val_loss: 2.1993 - val_acc: 0.3848\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.8287 - acc: 0.7100 - val_loss: 2.0010 - val_acc: 0.3995\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.8029 - acc: 0.7190 - val_loss: 2.0316 - val_acc: 0.3873\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.7674 - acc: 0.7322 - val_loss: 2.0094 - val_acc: 0.3853\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7259 - acc: 0.7457 - val_loss: 2.0554 - val_acc: 0.3944\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.6892 - acc: 0.7601 - val_loss: 2.4672 - val_acc: 0.3591\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 0.6587 - acc: 0.7729 - val_loss: 2.2462 - val_acc: 0.3845\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.6236 - acc: 0.7838 - val_loss: 2.0879 - val_acc: 0.4146\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 0.5994 - acc: 0.7935 - val_loss: 1.9449 - val_acc: 0.4149\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.5733 - acc: 0.8033 - val_loss: 2.0410 - val_acc: 0.4220\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.5297 - acc: 0.8183 - val_loss: 2.2229 - val_acc: 0.4137\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.5048 - acc: 0.8278 - val_loss: 2.1954 - val_acc: 0.4304\n",
      "Numbers of exp: 13, reduce_factor: 0.10, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.8388 - acc: 0.3530 - val_loss: 1.8484 - val_acc: 0.3627\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.5896 - acc: 0.4328 - val_loss: 1.6549 - val_acc: 0.4090\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.4944 - acc: 0.4660 - val_loss: 1.6099 - val_acc: 0.4279\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 1.4273 - acc: 0.4912 - val_loss: 1.7483 - val_acc: 0.3938\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.3691 - acc: 0.5143 - val_loss: 1.5026 - val_acc: 0.4686\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.3223 - acc: 0.5296 - val_loss: 1.6786 - val_acc: 0.4046\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.2811 - acc: 0.5456 - val_loss: 1.5955 - val_acc: 0.4253\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 1.2404 - acc: 0.5596 - val_loss: 1.5798 - val_acc: 0.4486\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.2000 - acc: 0.5751 - val_loss: 1.7050 - val_acc: 0.4049\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.1631 - acc: 0.5885 - val_loss: 1.4434 - val_acc: 0.4891\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1306 - acc: 0.6009 - val_loss: 1.5263 - val_acc: 0.4618\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.0997 - acc: 0.6111 - val_loss: 1.4959 - val_acc: 0.4796\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 1.0674 - acc: 0.6220 - val_loss: 1.5222 - val_acc: 0.4782\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.0342 - acc: 0.6326 - val_loss: 1.5353 - val_acc: 0.4647\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 1.0041 - acc: 0.6455 - val_loss: 1.5124 - val_acc: 0.4887\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.9757 - acc: 0.6543 - val_loss: 1.5403 - val_acc: 0.4700\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.9462 - acc: 0.6662 - val_loss: 1.5366 - val_acc: 0.4840\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 0.9116 - acc: 0.6796 - val_loss: 1.5522 - val_acc: 0.4714\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.8867 - acc: 0.6875 - val_loss: 1.7390 - val_acc: 0.4443\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.8585 - acc: 0.6979 - val_loss: 1.5340 - val_acc: 0.4803\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.8250 - acc: 0.7077 - val_loss: 1.6769 - val_acc: 0.4768\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.7900 - acc: 0.7203 - val_loss: 1.5845 - val_acc: 0.4841\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.7733 - acc: 0.7280 - val_loss: 1.6236 - val_acc: 0.4905\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.7404 - acc: 0.7387 - val_loss: 1.8959 - val_acc: 0.4491\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.7163 - acc: 0.7462 - val_loss: 1.8270 - val_acc: 0.4529\n",
      "Numbers of exp: 14, reduce_factor: 0.10, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 1.8226 - acc: 0.3559 - val_loss: 1.7431 - val_acc: 0.3945\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.5770 - acc: 0.4374 - val_loss: 1.7126 - val_acc: 0.3963\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.4796 - acc: 0.4744 - val_loss: 1.6372 - val_acc: 0.4307\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 1.4196 - acc: 0.4957 - val_loss: 1.5772 - val_acc: 0.4357\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 1.3712 - acc: 0.5124 - val_loss: 1.6789 - val_acc: 0.4145\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 1.3256 - acc: 0.5306 - val_loss: 2.0014 - val_acc: 0.3355\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 1.2808 - acc: 0.5450 - val_loss: 1.7465 - val_acc: 0.4016\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.2381 - acc: 0.5615 - val_loss: 1.5838 - val_acc: 0.4474\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.2008 - acc: 0.5753 - val_loss: 1.4929 - val_acc: 0.4730\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.1585 - acc: 0.5903 - val_loss: 1.5441 - val_acc: 0.4552\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.1246 - acc: 0.6024 - val_loss: 1.5554 - val_acc: 0.4596\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.0925 - acc: 0.6126 - val_loss: 1.5791 - val_acc: 0.4492\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.0532 - acc: 0.6287 - val_loss: 1.5012 - val_acc: 0.4693\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.0220 - acc: 0.6380 - val_loss: 1.4823 - val_acc: 0.4916\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.9924 - acc: 0.6517 - val_loss: 1.5692 - val_acc: 0.4663\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.9585 - acc: 0.6620 - val_loss: 1.6304 - val_acc: 0.4506\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.9243 - acc: 0.6753 - val_loss: 1.5689 - val_acc: 0.4719\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.8897 - acc: 0.6896 - val_loss: 1.5120 - val_acc: 0.4997\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.8574 - acc: 0.6977 - val_loss: 1.5717 - val_acc: 0.4757\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.8353 - acc: 0.7047 - val_loss: 1.5976 - val_acc: 0.4839\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.8075 - acc: 0.7173 - val_loss: 1.6644 - val_acc: 0.4674\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.7734 - acc: 0.7288 - val_loss: 1.5605 - val_acc: 0.5099\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.7397 - acc: 0.7407 - val_loss: 1.6036 - val_acc: 0.4949\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.7030 - acc: 0.7545 - val_loss: 1.7207 - val_acc: 0.4727\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6693 - acc: 0.7704 - val_loss: 1.7177 - val_acc: 0.4927\n",
      "Numbers of exp: 15, reduce_factor: 0.01, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.8331 - acc: 0.3539 - val_loss: 1.7969 - val_acc: 0.3668\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 1.5779 - acc: 0.4355 - val_loss: 1.6838 - val_acc: 0.4161\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.4910 - acc: 0.4685 - val_loss: 1.7046 - val_acc: 0.3888\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.4181 - acc: 0.4937 - val_loss: 1.6280 - val_acc: 0.4274\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.3640 - acc: 0.5116 - val_loss: 1.5560 - val_acc: 0.4525\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.3272 - acc: 0.5277 - val_loss: 1.6331 - val_acc: 0.4317\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.2742 - acc: 0.5460 - val_loss: 1.5083 - val_acc: 0.4677\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.2363 - acc: 0.5608 - val_loss: 1.6589 - val_acc: 0.4102\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.1928 - acc: 0.5742 - val_loss: 1.5109 - val_acc: 0.4589\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.1621 - acc: 0.5884 - val_loss: 1.4677 - val_acc: 0.4774\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.1293 - acc: 0.5979 - val_loss: 1.5381 - val_acc: 0.4554\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.0963 - acc: 0.6119 - val_loss: 1.4693 - val_acc: 0.4781\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0670 - acc: 0.6213 - val_loss: 1.4722 - val_acc: 0.4965\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0336 - acc: 0.6329 - val_loss: 1.5164 - val_acc: 0.4798\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.0029 - acc: 0.6423 - val_loss: 1.4849 - val_acc: 0.4878\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.9729 - acc: 0.6536 - val_loss: 1.5310 - val_acc: 0.4778\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.9357 - acc: 0.6668 - val_loss: 1.5127 - val_acc: 0.4913\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.9087 - acc: 0.6785 - val_loss: 1.5186 - val_acc: 0.4952\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.8792 - acc: 0.6904 - val_loss: 1.6039 - val_acc: 0.4714\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.8537 - acc: 0.6967 - val_loss: 1.5443 - val_acc: 0.4860\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.8199 - acc: 0.7097 - val_loss: 1.6221 - val_acc: 0.4667\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.7980 - acc: 0.7175 - val_loss: 1.6086 - val_acc: 0.4862\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.7541 - acc: 0.7357 - val_loss: 1.6037 - val_acc: 0.4889\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.7277 - acc: 0.7429 - val_loss: 1.6936 - val_acc: 0.4734\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.7006 - acc: 0.7544 - val_loss: 1.7260 - val_acc: 0.4740\n",
      "Numbers of exp: 16, reduce_factor: 0.01, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.8183 - acc: 0.3594 - val_loss: 1.8476 - val_acc: 0.3618\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.5638 - acc: 0.4412 - val_loss: 1.5762 - val_acc: 0.4464\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.4728 - acc: 0.4768 - val_loss: 1.5983 - val_acc: 0.4337\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.4125 - acc: 0.4946 - val_loss: 1.8390 - val_acc: 0.3740\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.3596 - acc: 0.5158 - val_loss: 1.4807 - val_acc: 0.4732\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.3063 - acc: 0.5340 - val_loss: 1.4971 - val_acc: 0.4640\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.2676 - acc: 0.5506 - val_loss: 1.5835 - val_acc: 0.4564\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.2214 - acc: 0.5664 - val_loss: 1.4515 - val_acc: 0.4872\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.1888 - acc: 0.5785 - val_loss: 1.4444 - val_acc: 0.4919\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.1552 - acc: 0.5905 - val_loss: 1.5675 - val_acc: 0.4490\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.1202 - acc: 0.6038 - val_loss: 1.5089 - val_acc: 0.4618\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0907 - acc: 0.6141 - val_loss: 1.7228 - val_acc: 0.4217\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0568 - acc: 0.6272 - val_loss: 1.4988 - val_acc: 0.4687\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0279 - acc: 0.6370 - val_loss: 1.4267 - val_acc: 0.5050\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.9906 - acc: 0.6513 - val_loss: 1.5225 - val_acc: 0.4858\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.9631 - acc: 0.6612 - val_loss: 1.5061 - val_acc: 0.4988\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.9331 - acc: 0.6710 - val_loss: 1.6436 - val_acc: 0.4601\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.9008 - acc: 0.6822 - val_loss: 1.4992 - val_acc: 0.4963\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8698 - acc: 0.6940 - val_loss: 1.6216 - val_acc: 0.4771\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.8352 - acc: 0.7062 - val_loss: 1.5881 - val_acc: 0.4746\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.8094 - acc: 0.7164 - val_loss: 1.6381 - val_acc: 0.4862\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.7778 - acc: 0.7279 - val_loss: 1.5667 - val_acc: 0.4993\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.7423 - acc: 0.7399 - val_loss: 1.6306 - val_acc: 0.4913\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.7054 - acc: 0.7534 - val_loss: 1.6385 - val_acc: 0.4901\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.6868 - acc: 0.7579 - val_loss: 1.7528 - val_acc: 0.4809\n",
      "Numbers of exp: 17, reduce_factor: 0.01, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 1.8393 - acc: 0.3546 - val_loss: 1.7692 - val_acc: 0.3729\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.5804 - acc: 0.4331 - val_loss: 1.6524 - val_acc: 0.4033\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.4875 - acc: 0.4704 - val_loss: 1.5741 - val_acc: 0.4379\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.4196 - acc: 0.4962 - val_loss: 1.5780 - val_acc: 0.4456\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.3655 - acc: 0.5132 - val_loss: 1.4993 - val_acc: 0.4677\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.3130 - acc: 0.5315 - val_loss: 1.5257 - val_acc: 0.4577\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.2775 - acc: 0.5458 - val_loss: 1.4840 - val_acc: 0.4685\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.2387 - acc: 0.5588 - val_loss: 1.6854 - val_acc: 0.4125\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.2024 - acc: 0.5729 - val_loss: 1.4957 - val_acc: 0.4694\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.1644 - acc: 0.5881 - val_loss: 1.5439 - val_acc: 0.4655\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.1229 - acc: 0.6031 - val_loss: 1.5890 - val_acc: 0.4387\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.0910 - acc: 0.6132 - val_loss: 1.5900 - val_acc: 0.4446\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0632 - acc: 0.6239 - val_loss: 1.5253 - val_acc: 0.4615\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.0375 - acc: 0.6311 - val_loss: 1.5779 - val_acc: 0.4743\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.0039 - acc: 0.6444 - val_loss: 1.4450 - val_acc: 0.5055\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.9647 - acc: 0.6575 - val_loss: 1.5278 - val_acc: 0.4957\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.9415 - acc: 0.6662 - val_loss: 1.5854 - val_acc: 0.4672\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.9072 - acc: 0.6824 - val_loss: 1.5124 - val_acc: 0.4923\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8792 - acc: 0.6887 - val_loss: 1.5707 - val_acc: 0.4733\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.8502 - acc: 0.6987 - val_loss: 1.5363 - val_acc: 0.5037\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.8136 - acc: 0.7137 - val_loss: 1.6133 - val_acc: 0.4771\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.7829 - acc: 0.7240 - val_loss: 1.6614 - val_acc: 0.4793\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7547 - acc: 0.7337 - val_loss: 1.6422 - val_acc: 0.4865\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7207 - acc: 0.7461 - val_loss: 1.6743 - val_acc: 0.4999\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.6931 - acc: 0.7577 - val_loss: 1.6066 - val_acc: 0.5004\n",
      "Numbers of exp: 18, reduce_factor: 0.00, reduce_patient: 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 1.8258 - acc: 0.3568 - val_loss: 1.7023 - val_acc: 0.4000\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.5716 - acc: 0.4401 - val_loss: 1.6774 - val_acc: 0.4091\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.4783 - acc: 0.4715 - val_loss: 1.7364 - val_acc: 0.3873\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.4205 - acc: 0.4941 - val_loss: 1.6112 - val_acc: 0.4259\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.3586 - acc: 0.5153 - val_loss: 1.5734 - val_acc: 0.4396\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.3140 - acc: 0.5343 - val_loss: 1.4663 - val_acc: 0.4749\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.2696 - acc: 0.5472 - val_loss: 1.5461 - val_acc: 0.4620\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.2321 - acc: 0.5615 - val_loss: 1.4889 - val_acc: 0.4705\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.1961 - acc: 0.5753 - val_loss: 1.6286 - val_acc: 0.4258\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.1542 - acc: 0.5915 - val_loss: 1.5709 - val_acc: 0.4470\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.1214 - acc: 0.6007 - val_loss: 1.4771 - val_acc: 0.4821\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0969 - acc: 0.6090 - val_loss: 1.4688 - val_acc: 0.4832\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0600 - acc: 0.6247 - val_loss: 1.4679 - val_acc: 0.4952\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0248 - acc: 0.6379 - val_loss: 1.4726 - val_acc: 0.4942\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0014 - acc: 0.6446 - val_loss: 1.5610 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.9630 - acc: 0.6605 - val_loss: 1.4673 - val_acc: 0.4939\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.9437 - acc: 0.6659 - val_loss: 1.5984 - val_acc: 0.4566\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.9171 - acc: 0.6741 - val_loss: 1.5780 - val_acc: 0.4697\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.8875 - acc: 0.6847 - val_loss: 1.5520 - val_acc: 0.4873\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.8546 - acc: 0.6966 - val_loss: 1.5446 - val_acc: 0.4855\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.8193 - acc: 0.7106 - val_loss: 1.5107 - val_acc: 0.4947\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.7935 - acc: 0.7181 - val_loss: 1.6441 - val_acc: 0.4806\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.7654 - acc: 0.7297 - val_loss: 1.6800 - val_acc: 0.4734\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.7304 - acc: 0.7433 - val_loss: 1.7733 - val_acc: 0.4689\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7064 - acc: 0.7534 - val_loss: 1.6458 - val_acc: 0.4812\n",
      "Numbers of exp: 19, reduce_factor: 0.00, reduce_patient: 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.8326 - acc: 0.3583 - val_loss: 1.8419 - val_acc: 0.3516\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.5867 - acc: 0.4385 - val_loss: 1.7128 - val_acc: 0.4035\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.4949 - acc: 0.4681 - val_loss: 1.5660 - val_acc: 0.4423\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 1.4233 - acc: 0.4932 - val_loss: 1.7307 - val_acc: 0.3831\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.3710 - acc: 0.5130 - val_loss: 1.6731 - val_acc: 0.4121\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.3191 - acc: 0.5305 - val_loss: 1.6061 - val_acc: 0.4323\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2772 - acc: 0.5459 - val_loss: 1.5242 - val_acc: 0.4541\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.2392 - acc: 0.5581 - val_loss: 1.4817 - val_acc: 0.4855\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.2020 - acc: 0.5734 - val_loss: 1.5163 - val_acc: 0.4719\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1647 - acc: 0.5858 - val_loss: 1.5356 - val_acc: 0.4549\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 1.1313 - acc: 0.5980 - val_loss: 1.4807 - val_acc: 0.4723\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.0940 - acc: 0.6122 - val_loss: 1.4849 - val_acc: 0.4819\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.0634 - acc: 0.6240 - val_loss: 1.5299 - val_acc: 0.4747\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.0314 - acc: 0.6375 - val_loss: 1.5158 - val_acc: 0.4814\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.0032 - acc: 0.6443 - val_loss: 1.4973 - val_acc: 0.4895\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.9717 - acc: 0.6559 - val_loss: 1.7517 - val_acc: 0.4241\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.9463 - acc: 0.6654 - val_loss: 1.5175 - val_acc: 0.4899\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.9086 - acc: 0.6799 - val_loss: 1.5667 - val_acc: 0.4781\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.8791 - acc: 0.6899 - val_loss: 1.6248 - val_acc: 0.4607\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.8636 - acc: 0.6929 - val_loss: 1.5656 - val_acc: 0.4911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.8261 - acc: 0.7101 - val_loss: 1.5401 - val_acc: 0.4955\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.8025 - acc: 0.7157 - val_loss: 1.8034 - val_acc: 0.4531\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.7679 - acc: 0.7312 - val_loss: 1.5720 - val_acc: 0.4986\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.7344 - acc: 0.7403 - val_loss: 1.6281 - val_acc: 0.4823\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.7034 - acc: 0.7534 - val_loss: 1.9026 - val_acc: 0.4688\n",
      "Numbers of exp: 20, reduce_factor: 0.00, reduce_patient: 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.8270 - acc: 0.3530 - val_loss: 1.8054 - val_acc: 0.3792\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 1.5920 - acc: 0.4311 - val_loss: 1.6259 - val_acc: 0.4222\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.4938 - acc: 0.4689 - val_loss: 1.5812 - val_acc: 0.4365\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.4260 - acc: 0.4900 - val_loss: 1.7066 - val_acc: 0.3876\n",
      "Epoch 5/25\n",
      "41984/50000 [========================>.....] - ETA: 1s - loss: 1.3765 - acc: 0.5111"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "results = {}\n",
    "for i, (optim, reduce_factor, reduce_patient) in enumerate(itertools.product(optimizer_set, reduce_lr_factor, redice_lr_patient)):\n",
    "    print(\"Numbers of exp: %i, reduce_factor: %.2f, reduce_patient: %i\" % (i, reduce_factor, reduce_patient))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optim)\n",
    "    \n",
    "    \"\"\"Code Here\n",
    "    設定 reduce learning rate 的 callback function\n",
    "    \"\"\"\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.5, \n",
    "                              min_lr=reduce_factor, \n",
    "                              monitor='val_loss', \n",
    "                              patience=reduce_patient, \n",
    "                              verbose=1)\n",
    "    \n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True,\n",
    "              callbacks=[reduce_lr]\n",
    "             )\n",
    "\n",
    "    # Collect results\n",
    "    exp_name_tag = (\"exp-%s\" % (i))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"acc\"],\n",
    "                             'valid-acc': model.history.history[\"val_acc\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "NUM_COLORS = len(results.keys())\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
